{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-11-12T20:52:36.350707Z",
     "iopub.status.busy": "2020-11-12T20:52:36.349693Z",
     "iopub.status.idle": "2020-11-12T20:52:37.673296Z",
     "shell.execute_reply": "2020-11-12T20:52:37.672571Z"
    },
    "papermill": {
     "duration": 1.362374,
     "end_time": "2020-11-12T20:52:37.673436",
     "exception": false,
     "start_time": "2020-11-12T20:52:36.311062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from IPython.display import FileLink\n",
    "from tqdm import tqdm_notebook \n",
    "from tqdm.notebook import tqdm\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "from joblib import Parallel, delayed\n",
    "from tsfresh.utilities.dataframe_functions import roll_time_series, make_forecasting_frame\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-11-12T20:52:37.731684Z",
     "iopub.status.busy": "2020-11-12T20:52:37.730409Z",
     "iopub.status.idle": "2020-11-12T20:52:37.7343Z",
     "shell.execute_reply": "2020-11-12T20:52:37.733629Z"
    },
    "papermill": {
     "duration": 0.035023,
     "end_time": "2020-11-12T20:52:37.734428",
     "exception": false,
     "start_time": "2020-11-12T20:52:37.699405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_file = 'training_files/result_{}.csv'\n",
    "super_train = 'super_train.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T20:52:37.797615Z",
     "iopub.status.busy": "2020-11-12T20:52:37.796784Z",
     "iopub.status.idle": "2020-11-12T20:52:39.321901Z",
     "shell.execute_reply": "2020-11-12T20:52:39.322521Z"
    },
    "papermill": {
     "duration": 1.561007,
     "end_time": "2020-11-12T20:52:39.32268",
     "exception": false,
     "start_time": "2020-11-12T20:52:37.761673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stock = 1\n",
    "df = pd.read_csv(train_file.format(stock), index_col='ID', parse_dates=['Date'])\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T20:52:39.384016Z",
     "iopub.status.busy": "2020-11-12T20:52:39.382875Z",
     "iopub.status.idle": "2020-11-12T20:52:39.57567Z",
     "shell.execute_reply": "2020-11-12T20:52:39.575028Z"
    },
    "papermill": {
     "duration": 0.225643,
     "end_time": "2020-11-12T20:52:39.575813",
     "exception": false,
     "start_time": "2020-11-12T20:52:39.35017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tdf = pd.read_csv(super_train, index_col='ID')\n",
    "\n",
    "tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T20:52:39.638177Z",
     "iopub.status.busy": "2020-11-12T20:52:39.637175Z",
     "iopub.status.idle": "2020-11-12T20:52:39.640333Z",
     "shell.execute_reply": "2020-11-12T20:52:39.639728Z"
    },
    "papermill": {
     "duration": 0.036108,
     "end_time": "2020-11-12T20:52:39.640467",
     "exception": false,
     "start_time": "2020-11-12T20:52:39.604359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print([i for i in df.columns if 'Open' == i])\n",
    "# print([i for i in df.columns if 'High' == i])\n",
    "# print([i for i in df.columns if 'Low' == i])\n",
    "# print([i for i in df.columns if 'holiday' == i])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T20:52:39.755936Z",
     "iopub.status.busy": "2020-11-12T20:52:39.716609Z",
     "iopub.status.idle": "2020-11-12T20:52:39.789255Z",
     "shell.execute_reply": "2020-11-12T20:52:39.788618Z"
    },
    "papermill": {
     "duration": 0.120778,
     "end_time": "2020-11-12T20:52:39.789401",
     "exception": false,
     "start_time": "2020-11-12T20:52:39.668623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.join(tdf[['Open_hat', 'High_hat', 'Low_hat', 'Close_hat']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [ \n",
    "    'holiday',\n",
    "    'stock',\n",
    "    'day',\n",
    "     'month',\n",
    "     'year',\n",
    "     'dayofweek',\n",
    "     'dayofyear',\n",
    "     'weekofyear',\n",
    "    'unpredictability_score']\n",
    "excluded_cols = ['Close_hat', 'Open_hat', 'High_hat', 'Low_hat']\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T20:52:39.857705Z",
     "iopub.status.busy": "2020-11-12T20:52:39.856521Z",
     "iopub.status.idle": "2020-11-12T20:52:39.860166Z",
     "shell.execute_reply": "2020-11-12T20:52:39.859404Z"
    },
    "papermill": {
     "duration": 0.041994,
     "end_time": "2020-11-12T20:52:39.860292",
     "exception": false,
     "start_time": "2020-11-12T20:52:39.818298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def expand_df(dframe):\n",
    "    dFrame = dframe.copy()\n",
    "    dFrame['day'] = dFrame.Date.apply(lambda x: x.day)\n",
    "    dFrame['month'] = dFrame.Date.apply(lambda x: x.month)\n",
    "    dFrame['year'] = dFrame.Date.apply(lambda x: x.year)\n",
    "    dFrame['dayofweek'] = dFrame.Date.apply(lambda x: x.dayofweek)\n",
    "    dFrame['dayofyear'] = dFrame.Date.apply(lambda x: x.dayofyear)\n",
    "    dFrame['weekofyear'] = dFrame.Date.apply(lambda x: x.weekofyear)\n",
    "    dFrame['year_diff'] = dFrame.Date.apply(lambda x: x.year - 2017)\n",
    "    dFrame['days_so_far_skipped'] = dFrame.Date.apply(lambda x: dFrame[dFrame.Date < x].shape[0])\n",
    "    dFrame['days_so_far'] = dFrame.Date.apply(lambda x: (x - pd.Timestamp('2017-01-03')).days)\n",
    "    return dFrame\n",
    "#     return dFrame[['Open_hat', 'High_hat', 'Low_hat', 'Close_hat'] + ['Date'] + cat_cols + ['year_diff', 'days_so_far_skipped', 'days_so_far'] + ['Close', 'Open', 'High', 'Low'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T20:52:39.922581Z",
     "iopub.status.busy": "2020-11-12T20:52:39.921755Z",
     "iopub.status.idle": "2020-11-12T20:52:43.438403Z",
     "shell.execute_reply": "2020-11-12T20:52:43.437671Z"
    },
    "papermill": {
     "duration": 3.549906,
     "end_time": "2020-11-12T20:52:43.43855",
     "exception": false,
     "start_time": "2020-11-12T20:52:39.888644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = expand_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T20:52:43.501465Z",
     "iopub.status.busy": "2020-11-12T20:52:43.500284Z",
     "iopub.status.idle": "2020-11-12T20:52:43.504098Z",
     "shell.execute_reply": "2020-11-12T20:52:43.503443Z"
    },
    "papermill": {
     "duration": 0.037008,
     "end_time": "2020-11-12T20:52:43.504236",
     "exception": false,
     "start_time": "2020-11-12T20:52:43.467228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for col in df.columns:\n",
    "#     if df[col].isna().sum() != 0: print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rolling_mean(dframe, col, idx, days=30, met='mean'):\n",
    "#     print(col, idx, days, met)\n",
    "    if met == 'mean':\n",
    "        return dframe[(dframe['days_so_far_skipped'] < dframe.loc[idx]['days_so_far_skipped'] + days) & (dframe['days_so_far_skipped'] >= dframe.loc[idx]['days_so_far_skipped'])][col].mean()\n",
    "    if met == 'max':\n",
    "        return dframe[(dframe['days_so_far_skipped'] < dframe.loc[idx]['days_so_far_skipped'] + days) & (dframe['days_so_far_skipped'] >= dframe.loc[idx]['days_so_far_skipped'])][col].max()\n",
    "    return dframe[(dframe['days_so_far_skipped'] < dframe.loc[idx]['days_so_far_skipped'] + days) & (dframe['days_so_far_skipped'] >= dframe.loc[idx]['days_so_far_skipped'])][col].min()\n",
    "\n",
    "def rolled_mean(dframe, timeshift=30):\n",
    "    dframe['ID'] = dframe.index\n",
    "\n",
    "    for col in excluded_cols:\n",
    "        dframe[col + '_roll_mean_per_mon'] = dframe['ID'].apply(lambda x: get_rolling_mean(dframe, col, x, days=timeshift, met='mean'))\n",
    "        dframe[col + '_roll_max_per_mon'] = dframe['ID'].apply(lambda x: get_rolling_mean(dframe, col, x, days=timeshift, met='max'))\n",
    "        dframe[col + '_roll_min_per_mon'] = dframe['ID'].apply(lambda x:get_rolling_mean(dframe, col, x, days=timeshift, met='min'))\n",
    "        dframe[col + '_roll_range_per_mon'] = dframe[col + '_roll_max_per_mon'] - dframe[col + '_roll_min_per_mon']\n",
    "        dframe[col + '_roll_mean_per_d'] = dframe['ID'].apply(lambda x: get_rolling_mean(dframe, col, x, days=2, met='mean'))\n",
    "        dframe[col + '_roll_max_per_d'] = dframe['ID'].apply(lambda x: get_rolling_mean(dframe, col, x, days=2, met='max'))\n",
    "        dframe[col + '_roll_min_per_d'] = dframe['ID'].apply(lambda x:get_rolling_mean(dframe, col, x, days=2, met='min'))\n",
    "        dframe[col + '_roll_range_per_d'] = dframe[col + '_roll_max_per_d'] - dframe[col + '_roll_min_per_d']\n",
    "    \n",
    "    return dframe.set_index('ID', drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolled_mean1(dframe):\n",
    "    dframe['ID'] = dframe.index\n",
    "\n",
    "    dFrame = dframe.copy()\n",
    "    dFrame = roll_time_series(dFrame, show_warnings=False, disable_progressbar=True, column_id='stock', column_sort='Date', max_timeshift=30, min_timeshift=0)\n",
    "    for col in excluded_cols:\n",
    "        dframe[col + '_roll_mean'] = dframe['ID'].apply(lambda x: dFrame[dFrame['ID'] == x][col].mean())\n",
    "        dframe[col + '_roll_max'] = dframe['ID'].apply(lambda x: dFrame[dFrame['ID'] == x][col].max())\n",
    "        dframe[col + '_roll_min'] = dframe['ID'].apply(lambda x: dFrame[dFrame['ID'] == x][col].min())\n",
    "        dframe[col + '_roll_range'] = dframe[col + '_roll_max'] - dframe[col + '_roll_min']\n",
    "        \n",
    "#     dframe['Close_hat'] = dframe['Close'].fillna(dframe[dframe['Close'].isna()]['Close_hat'])\n",
    "#     dframe['Open_hat'] = dframe['Open'].fillna(dframe[dframe['Close'].isna()]['Open_hat'])\n",
    "#     dframe['High_hat'] = dframe['High'].fillna(dframe[dframe['Close'].isna()]['High_hat'])\n",
    "#     dframe['Low_hat'] = dframe['Low'].fillna(dframe[dframe['Close'].isna()]['Low_hat'])\n",
    "    \n",
    "            \n",
    "    \n",
    "    return dframe.set_index('ID', drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = rolled_mean(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = rolled_mean(df)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Close_hat'].equals(df['Close_hat_roll_mean_per_mon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df['Close_hat'] - df['Close_hat_roll_mean_per_mon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df[df['Close'].notna()]['Close'] - df[df['Close'].notna()]['Close_hat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T20:52:43.572309Z",
     "iopub.status.busy": "2020-11-12T20:52:43.571342Z",
     "iopub.status.idle": "2020-11-12T20:52:43.576592Z",
     "shell.execute_reply": "2020-11-12T20:52:43.575898Z"
    },
    "papermill": {
     "duration": 0.041863,
     "end_time": "2020-11-12T20:52:43.576717",
     "exception": false,
     "start_time": "2020-11-12T20:52:43.534854",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "[col for col in tdf.columns.tolist() if col in set(excluded_cols)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ['mean', 'maximum', 'minimum']\n",
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T20:52:43.735376Z",
     "iopub.status.busy": "2020-11-12T20:52:43.711408Z",
     "iopub.status.idle": "2020-11-12T20:52:43.783771Z",
     "shell.execute_reply": "2020-11-12T20:52:43.781747Z"
    },
    "papermill": {
     "duration": 0.108739,
     "end_time": "2020-11-12T20:52:43.783908",
     "exception": false,
     "start_time": "2020-11-12T20:52:43.675169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "for col in tqdm(cat_cols):\n",
    "    df[col] = encoder.fit_transform(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T20:52:43.853003Z",
     "iopub.status.busy": "2020-11-12T20:52:43.852041Z",
     "iopub.status.idle": "2020-11-12T20:52:43.855088Z",
     "shell.execute_reply": "2020-11-12T20:52:43.855682Z"
    },
    "papermill": {
     "duration": 0.041349,
     "end_time": "2020-11-12T20:52:43.855918",
     "exception": false,
     "start_time": "2020-11-12T20:52:43.814569",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df['train'] = df['Close'].apply(lambda x: not pd.isna(x))\n",
    "# df.columns = [i.replace('{', '_').replace('}', '_') for i in df.columns]\n",
    "df.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T20:52:43.92741Z",
     "iopub.status.busy": "2020-11-12T20:52:43.926637Z",
     "iopub.status.idle": "2020-11-12T20:52:44.025542Z",
     "shell.execute_reply": "2020-11-12T20:52:44.026231Z"
    },
    "papermill": {
     "duration": 0.139396,
     "end_time": "2020-11-12T20:52:44.026419",
     "exception": false,
     "start_time": "2020-11-12T20:52:43.887023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X, y = df[df['Close'].notna()].drop(columns=['Close', 'Open', 'High', 'Low'], axis=1), df[['Close', 'stock']][df['Close'].notna()]\n",
    "X_test, y_test = df[df['Close'].isna()].drop(columns=['Close', 'Open', 'High', 'Low'], axis=1), df[['Close', 'stock']][df['Close'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['days_so_far']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T20:52:44.116084Z",
     "iopub.status.busy": "2020-11-12T20:52:44.115189Z",
     "iopub.status.idle": "2020-11-12T20:52:44.184151Z",
     "shell.execute_reply": "2020-11-12T20:52:44.183278Z"
    },
    "papermill": {
     "duration": 0.126234,
     "end_time": "2020-11-12T20:52:44.184283",
     "exception": false,
     "start_time": "2020-11-12T20:52:44.058049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Close_hat_roll_mean_per_mon'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Close_hat_roll_min_per_mon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T20:52:44.263991Z",
     "iopub.status.busy": "2020-11-12T20:52:44.262937Z",
     "iopub.status.idle": "2020-11-12T20:52:44.26836Z",
     "shell.execute_reply": "2020-11-12T20:52:44.26778Z"
    },
    "papermill": {
     "duration": 0.051175,
     "end_time": "2020-11-12T20:52:44.268506",
     "exception": false,
     "start_time": "2020-11-12T20:52:44.217331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T20:52:44.345123Z",
     "iopub.status.busy": "2020-11-12T20:52:44.344188Z",
     "iopub.status.idle": "2020-11-12T20:54:06.675365Z",
     "shell.execute_reply": "2020-11-12T20:54:06.676539Z"
    },
    "papermill": {
     "duration": 82.374626,
     "end_time": "2020-11-12T20:54:06.676757",
     "exception": false,
     "start_time": "2020-11-12T20:52:44.302131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hyper_params = {\n",
    "#     'task': 'train',\n",
    "#     'boosting_type': 'gbdt',\n",
    "#     'objective': 'regression',\n",
    "#     'metric': ['rmse'],\n",
    "#     'learning_rate': 0.1,\n",
    "#     'feature_fraction': 0.9,\n",
    "#     'bagging_fraction': 0.7,\n",
    "#     'bagging_freq': 10,\n",
    "#     'verbose': 0,\n",
    "#     \"max_depth\": 4,\n",
    "#     \"num_leaves\": 128,  \n",
    "#     \"max_bin\": 512,\n",
    "#     \"num_iterations\": 100000,\n",
    "#     \"n_estimators\": 1000,\n",
    "#     \"random_state\": 32\n",
    "# }\n",
    "# model_store = [0] * 103\n",
    "# metrics = [0] * 103\n",
    "# preds = []\n",
    "# # for stock in tqdm(X.stock.unique(), total=103):\n",
    "# for stock in tqdm(range(103), total=103):\n",
    "# # for stock in tqdm([1]):\n",
    "#     df = pd.read_csv(train_file.format(stock), index_col='ID', parse_dates=['Date'])\n",
    "#     df = expand_df(df)\n",
    "#     encoder = LabelEncoder()\n",
    "#     for col in cat_cols:\n",
    "#         df[col] = encoder.fit_transform(df[col])\n",
    "        \n",
    "#     df.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in df.columns]\n",
    "#     X, y = df[df['Close'].notna()].drop(columns=['Close', 'Open', 'High', 'Low'], axis=1), df[['Close', 'stock']][df['Close'].notna()]\n",
    "#     X_test, y_test = df[df['Close'].isna()].drop(columns=['Close', 'Open', 'High', 'Low'], axis=1), df[['Close', 'stock']][df['Close'].isna()]\n",
    "    \n",
    "    \n",
    "#     X_tr, X_val, y_tr, y_val = train_test_split(X.drop(columns=['Date']), y['Close'], train_size=0.80, random_state=11568)\n",
    "    \n",
    "    \n",
    "#     model_store[stock] = lgb.LGBMRegressor(**hyper_params)\n",
    "#     model_store[stock].fit(X_tr, \n",
    "#                            y_tr,\n",
    "#                            eval_set=[(X_val, y_val)],\n",
    "#                            eval_metric='rmse',\n",
    "#                            early_stopping_rounds=100,\n",
    "#                            verbose=False,\n",
    "#                            )\n",
    "#     metrics[stock] = list(list(model_store[stock].best_score_.values())[0].values())[0]\n",
    "#     print(stock, metrics[stock])\n",
    "#     preds.append(pd.DataFrame({'ID': X_test.index, 'Close': model_store[stock].predict(X_test.drop(columns=['Date']), num_iteration=model_store[stock].best_iteration_)}))\n",
    "\n",
    "\n",
    "\n",
    "# # pd.concat(preds).to_csv('result.csv', index=False)\n",
    "# # FileLink('result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return abs(mean_squared_error(y_true, y_pred, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_store1 = [0] * 103\n",
    "metrics1 = [0] * 103\n",
    "# df = None\n",
    "\n",
    "params = {'learning_rate': [.3, .35, .45], 'depth': [2, 3], 'od_wait': [15, 20, 25]}\n",
    "\n",
    "\n",
    "preds1 = []\n",
    "\n",
    "def get_predictions(stock):\n",
    "    df = pd.read_csv(train_file.format(stock), index_col='ID', parse_dates=['Date'])\n",
    "    df = df.join(tdf[['Open_hat', 'High_hat', 'Low_hat', 'Close_hat']])\n",
    "    df = expand_df(df)\n",
    "\n",
    "    df = rolled_mean(df)\n",
    "\n",
    "    encoder = LabelEncoder()\n",
    "    for col in cat_cols:\n",
    "        df[col] = encoder.fit_transform(df[col])\n",
    "\n",
    "    df.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in df.columns]\n",
    "\n",
    "    X, y = df[df['Close'].notna()].drop(columns=['Close', 'Open', 'High', 'Low'], axis=1), df[['Close', 'stock']][df['Close'].notna()]\n",
    "    X_test, y_test = df[df['Close'].isna()].drop(columns=['Close', 'Open', 'High', 'Low'], axis=1), df[['Close', 'stock']][df['Close'].isna()]\n",
    "\n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(X, y['Close'], train_size=.8, random_state=11568)\n",
    "    model = CatBoostRegressor(\n",
    "        loss_function='RMSE', \n",
    "#         depth=2, \n",
    "#         learning_rate=0.4, \n",
    "        iterations=800,\n",
    "        random_seed=18,\n",
    "        od_type='Iter',\n",
    "#         od_wait=20,\n",
    "        thread_count=1,# task_type=\"GPU\"\n",
    "    )\n",
    "    \n",
    "    \n",
    "#     model.fit(\n",
    "#         X_tr, y_tr, use_best_model=True,\n",
    "#         cat_features=cat_cols,\n",
    "#         eval_set=(X_val, y_val),\n",
    "#         verbose=False,\n",
    "#         plot=False,\n",
    "#     )\n",
    "    grid = GridSearchCV(estimator=model, param_grid=params, cv=2, n_jobs=2, \n",
    "                        scoring=make_scorer(rmse, greater_is_better=False), verbose=0)\n",
    "    grid.fit(\n",
    "        X, y['Close']\n",
    "    )\n",
    "# #     model_store1[stock] = grid\n",
    "#     print(\"best_params\")\n",
    "#     metrics1[stock] = grid.best_params_\n",
    "\n",
    "    return pd.DataFrame({'Params': str(grid.best_params_), 'Score': grid.best_score_, 'ID': X_test.index, 'Close': grid.predict(X_test)})\n",
    "\n",
    "\n",
    "num_cores = 4\n",
    "preds1 = Parallel(n_jobs=num_cores)(delayed(get_predictions)(stock) for stock in tqdm(range(103)))\n",
    "# preds1 = [get_predictions(stock) for stock in tqdm(range(1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1[0]['Params'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T20:54:07.060991Z",
     "iopub.status.busy": "2020-11-12T20:54:07.060164Z",
     "iopub.status.idle": "2020-11-12T20:55:18.11094Z",
     "shell.execute_reply": "2020-11-12T20:55:18.107377Z"
    },
    "papermill": {
     "duration": 71.150758,
     "end_time": "2020-11-12T20:55:18.111106",
     "exception": false,
     "start_time": "2020-11-12T20:54:06.960348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_store = [0] * 103\n",
    "metrics = [0] * 103\n",
    "\n",
    "preds = []\n",
    "\n",
    "parameters = {#'nthread':[1], #when use hyperthread, xgboost may become slower\n",
    "              'objective':['reg:squarederror'],\n",
    "              'learning_rate': [.1, .2, .3], #so called `eta` value\n",
    "              'max_depth': [7, 8, 6],\n",
    "              'min_child_weight': [4],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.7],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [500]}\n",
    "\n",
    "\n",
    "def get_predictions1(stock):\n",
    "    df = pd.read_csv(train_file.format(stock), index_col='ID', parse_dates=['Date'])\n",
    "    df = df.join(tdf[['Open_hat', 'High_hat', 'Low_hat', 'Close_hat']])\n",
    "    df = expand_df(df)\n",
    "\n",
    "    df = rolled_mean(df)\n",
    "\n",
    "    encoder = LabelEncoder()\n",
    "    for col in cat_cols:\n",
    "        df[col] = encoder.fit_transform(df[col])\n",
    "\n",
    "    df.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in df.columns]\n",
    "\n",
    "    X, y = df[df['Close'].notna()].drop(columns=['Close', 'Open', 'High', 'Low'], axis=1), df[['Close', 'stock']][df['Close'].notna()]\n",
    "    X_test, y_test = df[df['Close'].isna()].drop(columns=['Close', 'Open', 'High', 'Low'], axis=1), df[['Close', 'stock']][df['Close'].isna()]\n",
    "\n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(X, y['Close'], train_size=.8, random_state=11568)\n",
    "    model = XGBRegressor(tree_method='gpu_hist', gpu_id=0)\n",
    "    \n",
    "    xgb_grid = GridSearchCV(model,\n",
    "                           parameters,\n",
    "                           cv=2,\n",
    "                           n_jobs=1,\n",
    "                           scoring=make_scorer(rmse, greater_is_better=False),\n",
    "                           verbose=False\n",
    "                           )\n",
    "    \n",
    "    xgb_grid.fit(\n",
    "        X.drop('Date', axis=1), y['Close']\n",
    "    )\n",
    "#     model_store[stock] = xgb_grid\n",
    "#     metrics[stock] = xgb_grid.best_score_\n",
    "#     print(str(xgb_grid.best_params_))\n",
    "    return pd.DataFrame({'Params': str(xgb_grid.best_params_), 'Score': abs(xgb_grid.best_score_), 'ID': X_test.index, 'Close': xgb_grid.predict(X_test.drop('Date', axis=1))})\n",
    "\n",
    "\n",
    "num_cores = 16\n",
    "# preds = Parallel(n_jobs=num_cores)(delayed(get_predictions1)(stock) for stock in tqdm(range(103)))\n",
    "\n",
    "# preds = [get_predictions1(stock) for stock in tqdm(range(1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T20:55:18.861766Z",
     "iopub.status.busy": "2020-11-12T20:55:18.857593Z",
     "iopub.status.idle": "2020-11-12T20:55:21.314451Z",
     "shell.execute_reply": "2020-11-12T20:55:21.313431Z"
    },
    "papermill": {
     "duration": 2.587835,
     "end_time": "2020-11-12T20:55:21.314671",
     "exception": false,
     "start_time": "2020-11-12T20:55:18.726836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# preds = []\n",
    "# for stock in X.stock.unique(): \n",
    "\n",
    "# # for stock in [1]:\n",
    "#     pred1 = model_store[stock].predict(X_test[X_test['stock'] == stock].drop(columns=['Date']), num_iteration=model_store[stock].best_iteration_)\n",
    "#     pred2 = model_store1[stock].predict(X_test[X_test['stock'] == stock])\n",
    "    \n",
    "#     if metrics[stock] > metrics1[stock]:\n",
    "#         print(\"picked first\")\n",
    "# #         preds.append(pd.DataFrame({'ID': X_test[X_test['stock'] == stock].index, 'Close': model_store1[stock].predict(X_test[X_test['stock'] == stock])}))\n",
    "#         preds.append(pd.DataFrame({'ID': X_test[X_test['stock'] == stock].index, 'Close': (pred2 * 7 + pred1) / 8}))\n",
    "    \n",
    "#     else:\n",
    "#         print(\"picked second\")\n",
    "# #         preds.append(pd.DataFrame({'ID': X_test[X_test['stock'] == stock].index, 'Close': model_store[stock].predict(X_test[X_test['stock'] == stock].drop(columns=['Date']), num_iteration=model_store[stock].best_iteration_)}))\n",
    "#         preds.append(pd.DataFrame({'ID': X_test[X_test['stock'] == stock].index, 'Close': (pred2 * 4 + pred1) / 5}))\n",
    "    \n",
    "\n",
    "pd.concat(preds1)[['ID', 'Close']].to_csv('result_latest.csv', index=False)\n",
    "\n",
    "pd.concat(preds1).to_csv('result_catboost_analysis_latest.csv', index=False)\n",
    "\n",
    "# pd.concat(preds)[['ID', 'Close']].to_csv('result1.csv', index=False)\n",
    "# pd.concat(preds1).shape       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(preds1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.concat(preds)['Params'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T20:55:21.587251Z",
     "iopub.status.busy": "2020-11-12T20:55:21.586373Z",
     "iopub.status.idle": "2020-11-12T20:55:21.59091Z",
     "shell.execute_reply": "2020-11-12T20:55:21.590259Z"
    },
    "papermill": {
     "duration": 0.140501,
     "end_time": "2020-11-12T20:55:21.591037",
     "exception": false,
     "start_time": "2020-11-12T20:55:21.450536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "FileLink('result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FileLink('result1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T20:55:21.840549Z",
     "iopub.status.busy": "2020-11-12T20:55:21.839753Z",
     "iopub.status.idle": "2020-11-12T20:55:22.622481Z",
     "shell.execute_reply": "2020-11-12T20:55:22.621435Z"
    },
    "papermill": {
     "duration": 0.90897,
     "end_time": "2020-11-12T20:55:22.622711",
     "exception": false,
     "start_time": "2020-11-12T20:55:21.713741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "!cat result_latest.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for stock in X_test.stock.unique():\n",
    "# !cat result1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat result_catboost_analysis_latest.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
