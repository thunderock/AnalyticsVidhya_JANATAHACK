{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashutosh/miniconda3/lib/python3.7/site-packages/tqdm/std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SELF-INDICATOR</th>\n",
       "      <th>MATCH-TYPE</th>\n",
       "      <th>ACCT-TYPE</th>\n",
       "      <th>CONTRIBUTOR-TYPE</th>\n",
       "      <th>DATE-REPORTED</th>\n",
       "      <th>OWNERSHIP-IND</th>\n",
       "      <th>ACCOUNT-STATUS</th>\n",
       "      <th>DISBURSED-DT</th>\n",
       "      <th>CLOSE-DT</th>\n",
       "      <th>...</th>\n",
       "      <th>OVERDUE-AMT</th>\n",
       "      <th>WRITE-OFF-AMT</th>\n",
       "      <th>ASSET_CLASS</th>\n",
       "      <th>REPORTED DATE - HIST</th>\n",
       "      <th>DPD - HIST</th>\n",
       "      <th>CUR BAL - HIST</th>\n",
       "      <th>AMT OVERDUE - HIST</th>\n",
       "      <th>AMT PAID - HIST</th>\n",
       "      <th>TENURE</th>\n",
       "      <th>INSTALLMENT-TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>PRIMARY</td>\n",
       "      <td>Overdraft</td>\n",
       "      <td>NAB</td>\n",
       "      <td>2018-04-30</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Delinquent</td>\n",
       "      <td>2015-10-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>37873.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Standard</td>\n",
       "      <td>20180430,20180331,</td>\n",
       "      <td>030000</td>\n",
       "      <td>37873,12820,</td>\n",
       "      <td>37873,,</td>\n",
       "      <td>,,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>PRIMARY</td>\n",
       "      <td>Auto Loan (Personal)</td>\n",
       "      <td>NAB</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Active</td>\n",
       "      <td>2018-03-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Standard</td>\n",
       "      <td>20191231,20191130,20191031,20190930,20190831,2...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>20797,21988,23174,24341,25504,26648,27780,2891...</td>\n",
       "      <td>,,,,,,,,,,,,,,,,,,,,1452,,</td>\n",
       "      <td>,,,,,,,,,,,,,,,,,,,,,,</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Monthly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>PRIMARY</td>\n",
       "      <td>Tractor Loan</td>\n",
       "      <td>NBF</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Active</td>\n",
       "      <td>2019-08-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20200131,20191231,20191130,20191031,20190930,2...</td>\n",
       "      <td>000000000000000000</td>\n",
       "      <td>116087,116087,145000,145000,145000,145000,</td>\n",
       "      <td>0,0,0,0,0,0,</td>\n",
       "      <td>,,,,,,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>PRIMARY</td>\n",
       "      <td>Auto Loan (Personal)</td>\n",
       "      <td>NBF</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2013-09-27</td>\n",
       "      <td>2017-09-21</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20170930,20170801,20170731,20170630,20170531,2...</td>\n",
       "      <td>000DDD0270260270260270240270270000320000000000...</td>\n",
       "      <td>0,,15925,23754,31494,39147,46713,54194,61590,6...</td>\n",
       "      <td>0,,1014,1014,1014,1014,1014,1014,1014,983,0,92...</td>\n",
       "      <td>,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>PRIMARY</td>\n",
       "      <td>Tractor Loan</td>\n",
       "      <td>NBF</td>\n",
       "      <td>2016-02-29</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2012-02-10</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160229,20160131,20151231,20151130,20151031,2...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0,0,23658,23321,22989,46321,45662,45012,68030,...</td>\n",
       "      <td>0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...</td>\n",
       "      <td>,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  SELF-INDICATOR MATCH-TYPE             ACCT-TYPE CONTRIBUTOR-TYPE  \\\n",
       "0   1           False    PRIMARY             Overdraft              NAB   \n",
       "1   1           False    PRIMARY  Auto Loan (Personal)              NAB   \n",
       "2   1            True    PRIMARY          Tractor Loan              NBF   \n",
       "3   1            True    PRIMARY  Auto Loan (Personal)              NBF   \n",
       "4   1            True    PRIMARY          Tractor Loan              NBF   \n",
       "\n",
       "  DATE-REPORTED OWNERSHIP-IND ACCOUNT-STATUS DISBURSED-DT    CLOSE-DT  ...  \\\n",
       "0    2018-04-30    Individual     Delinquent   2015-10-05         NaN  ...   \n",
       "1    2019-12-31    Individual         Active   2018-03-19         NaN  ...   \n",
       "2    2020-01-31    Individual         Active   2019-08-30         NaN  ...   \n",
       "3    2017-09-30    Individual         Closed   2013-09-27  2017-09-21  ...   \n",
       "4    2016-02-29    Individual         Closed   2012-02-10  2016-02-01  ...   \n",
       "\n",
       "  OVERDUE-AMT  WRITE-OFF-AMT  ASSET_CLASS  \\\n",
       "0     37873.0            0.0     Standard   \n",
       "1         NaN            0.0     Standard   \n",
       "2         0.0            0.0          NaN   \n",
       "3         0.0            0.0          NaN   \n",
       "4         0.0            0.0          NaN   \n",
       "\n",
       "                                REPORTED DATE - HIST  \\\n",
       "0                                 20180430,20180331,   \n",
       "1  20191231,20191130,20191031,20190930,20190831,2...   \n",
       "2  20200131,20191231,20191130,20191031,20190930,2...   \n",
       "3  20170930,20170801,20170731,20170630,20170531,2...   \n",
       "4  20160229,20160131,20151231,20151130,20151031,2...   \n",
       "\n",
       "                                          DPD - HIST  \\\n",
       "0                                             030000   \n",
       "1  0000000000000000000000000000000000000000000000...   \n",
       "2                                 000000000000000000   \n",
       "3  000DDD0270260270260270240270270000320000000000...   \n",
       "4  0000000000000000000000000000000000000000000000...   \n",
       "\n",
       "                                      CUR BAL - HIST  \\\n",
       "0                                       37873,12820,   \n",
       "1  20797,21988,23174,24341,25504,26648,27780,2891...   \n",
       "2         116087,116087,145000,145000,145000,145000,   \n",
       "3  0,,15925,23754,31494,39147,46713,54194,61590,6...   \n",
       "4  0,0,23658,23321,22989,46321,45662,45012,68030,...   \n",
       "\n",
       "                                  AMT OVERDUE - HIST  \\\n",
       "0                                            37873,,   \n",
       "1                         ,,,,,,,,,,,,,,,,,,,,1452,,   \n",
       "2                                       0,0,0,0,0,0,   \n",
       "3  0,,1014,1014,1014,1014,1014,1014,1014,983,0,92...   \n",
       "4  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...   \n",
       "\n",
       "                         AMT PAID - HIST TENURE INSTALLMENT-TYPE  \n",
       "0                                     ,,    NaN              NaN  \n",
       "1                 ,,,,,,,,,,,,,,,,,,,,,,   36.0          Monthly  \n",
       "2                                 ,,,,,,    NaN              NaN  \n",
       "3  ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,    NaN              NaN  \n",
       "4  ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,    NaN              NaN  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "df = pd.read_csv(\"Train/cleaned_bureau.csv\")\n",
    "tdf = pd.read_csv(\"Test/cleaned_bureau.csv\")\n",
    "train_df = pd.read_csv(\"Train/cleaned_train.csv\")\n",
    "test_df = pd.read_csv(\"Test/cleaned_train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71060     420\n",
       "141732    165\n",
       "51786     152\n",
       "1167      138\n",
       "97794     124\n",
       "         ... \n",
       "107223      1\n",
       "109270      1\n",
       "116205      1\n",
       "103121      1\n",
       "9436        1\n",
       "Name: ID, Length: 128655, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ID.value_counts(sort=True, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114111    93\n",
       "114063    60\n",
       "69953     59\n",
       "26305     59\n",
       "114125    56\n",
       "          ..\n",
       "78473      1\n",
       "141962     1\n",
       "62097      1\n",
       "141994     1\n",
       "98272      1\n",
       "Name: ID, Length: 14745, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdf.ID.value_counts(sort=True, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['SELF-INDICATOR', 'MATCH-TYPE', 'ACCT-TYPE', 'CONTRIBUTOR-TYPE',\n",
    "       'OWNERSHIP-IND', 'ACCOUNT-STATUS', 'INSTALLMENT-TYPE',\n",
    "       'ASSET_CLASS', 'INSTALLMENT-FREQUENCY',\n",
    "       'DPD - HIST']    #should not be here\n",
    "date_cols = ['DATE-REPORTED',  'DISBURSED-DT', 'CLOSE-DT', \n",
    "             'LAST-PAYMENT-DATE']\n",
    "reg_cols = ['CREDIT-LIMIT/SANC AMT', 'DISBURSED-AMT/HIGH CREDIT', 'INSTALLMENT-AMT', 'CURRENT-BAL',\n",
    "        'OVERDUE-AMT', 'WRITE-OFF-AMT', 'TENURE'] # , 'DPD - HIST']\n",
    "array_cols = ['REPORTED DATE - HIST', 'CUR BAL - HIST',\n",
    "       'AMT OVERDUE - HIST', 'AMT PAID - HIST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, (560844, 26))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat_cols) + len(date_cols) + len(reg_cols) + len(array_cols), df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all([df[i].dtype in (\"bool\" ,\"object\") for i in cat_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all([df[i].dtype == \"float64\" for i in reg_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATE-REPORTED          3683\n",
       "DISBURSED-DT          32150\n",
       "CLOSE-DT             251827\n",
       "LAST-PAYMENT-DATE    319283\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[date_cols].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATE-REPORTED          3683\n",
       "DISBURSED-DT          32150\n",
       "CLOSE-DT             251827\n",
       "LAST-PAYMENT-DATE    319283\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in date_cols:\n",
    "    df[col] = pd.to_datetime(df[col])\n",
    "    tdf[col] = pd.to_datetime(tdf[col])\n",
    "df[date_cols].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max train 37.0\n",
      "max test 37.0\n",
      "max train 37.0\n",
      "max test 37.0\n",
      "max train 42.0\n",
      "max test 37.0\n",
      "max train 38.0\n",
      "max test 38.0\n"
     ]
    }
   ],
   "source": [
    "def get_length(amt):    \n",
    "    if not pd.isnull(amt):\n",
    "        return len(amt.split(\",\"))\n",
    "    else: 0\n",
    "        \n",
    "for col in array_cols:\n",
    "    print(\"max train {}\".format(df[col].apply(lambda x: get_length(x)).max()))\n",
    "    \n",
    "    print(\"max test {}\".format(tdf[col].apply(lambda x: get_length(x)).max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_window = 420\n",
    "ts_feature_vector = 205\n",
    "max_array_size = 42\n",
    "label_encoder_dict = {}\n",
    "\n",
    "def encode_reg_cols(x):\n",
    "    if pd.isnull(x):\n",
    "        return 0.\n",
    "    return x\n",
    "\n",
    "def encode_array_cols(x):\n",
    "    if pd.isnull(x):\n",
    "        return [0] * max_array_size\n",
    "    else:\n",
    "        ret = []\n",
    "        for val in x.split(\",\"):\n",
    "            try:\n",
    "                ret.append(float(val))\n",
    "            except:\n",
    "                ret.append(0.)\n",
    "        while len(ret) < max_array_size:\n",
    "            ret.append(0.)\n",
    "        return ret\n",
    "\n",
    "\n",
    "def encode_date_cols(x):\n",
    "    if pd.isnull(x):\n",
    "        return [-1, -1, -1, -1, -1]\n",
    "    else:\n",
    "        return [x.hour, x.minute, x.day, x.month, x.year]\n",
    "\n",
    "\n",
    "def encode_cat_cols(x, col):\n",
    "\n",
    "    if pd.isnull(x): x = str(x)\n",
    "    return label_encoder_dict[col].transform([x])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23293df511c84c659e713ec8aa51c6fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELF-INDICATOR\n",
      "MATCH-TYPE\n",
      "ACCT-TYPE\n",
      "CONTRIBUTOR-TYPE\n",
      "OWNERSHIP-IND\n",
      "ACCOUNT-STATUS\n",
      "INSTALLMENT-TYPE\n",
      "ASSET_CLASS\n",
      "INSTALLMENT-FREQUENCY\n",
      "DPD - HIST\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for col in tqdm(cat_cols):\n",
    "    if col not in label_encoder_dict:\n",
    "        label_encoder_dict[col] = LabelEncoder()\n",
    "    print(col)\n",
    "    label_encoder_dict[col].fit(df[col].append(tdf[col]).fillna(\"nan\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = df[df.ID == 141732]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_df_for_user(dframe):\n",
    "    \n",
    "    final = []\n",
    "    for index, row in dframe.iterrows():\n",
    "        ret = []\n",
    "    \n",
    "        # 10 * 1\n",
    "        for col in cat_cols:\n",
    "            ret.extend(encode_cat_cols(row[col], col))\n",
    "        \n",
    "        # 7 * 1 = 7\n",
    "        for col in reg_cols:\n",
    "            ret.append(encode_reg_cols(row[col]))\n",
    "        \n",
    "        # 5 * 4 = 20\n",
    "        for col in date_cols:\n",
    "            \n",
    "            ret.extend(encode_date_cols(row[col]))\n",
    "        \n",
    "        \n",
    "        # 4 * 42 = 168\n",
    "        for col in array_cols:\n",
    "            ret.extend(encode_array_cols(row[col]))\n",
    "        \n",
    "        assert len(ret) == ts_feature_vector\n",
    "        final.append(ret)\n",
    "    while len(final) < max_window:\n",
    "        final.insert(0, [0.] * ts_feature_vector)\n",
    "    assert len(final) == max_window\n",
    "    return np.array(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(420, 205)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_df_for_user(temp_df).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4545b6bb16034392b0c5840a06e09084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency\n",
      "InstlmentMode\n",
      "LoanStatus\n",
      "PaymentMode\n",
      "BranchID\n",
      "Area\n",
      "ManufacturerID\n",
      "SupplierID\n",
      "SEX\n",
      "City\n",
      "State\n",
      "ZiPCODE\n",
      "Top-up Month\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_label_encoders = {}\n",
    "\n",
    "\n",
    "\n",
    "train_cat_cols = ['Frequency', 'InstlmentMode', 'LoanStatus', 'PaymentMode', 'BranchID', 'Area', \n",
    "            'ManufacturerID', 'SupplierID', 'SEX', 'City', 'State', 'ZiPCODE', 'Top-up Month']\n",
    "target_col = ['Top-up Month']\n",
    "train_reg_cols = ['AmountFinance', 'DisbursalAmount', 'EMI', 'AssetID', 'MonthlyIncome', 'Tenure', 'AssetCost', 'LTV', 'AGE']\n",
    "train_date_cols = ['DisbursalDate', 'MaturityDAte', 'AuthDate']\n",
    "\n",
    "for col in train_date_cols:\n",
    "    train_df[col] = pd.to_datetime(train_df[col], errors=\"coerce\")\n",
    "    test_df[col] = pd.to_datetime(test_df[col], errors=\"coerce\")\n",
    "    \n",
    "for col in tqdm(train_cat_cols):\n",
    "    if col not in train_label_encoders:\n",
    "        train_label_encoders[col] = LabelEncoder()\n",
    "    print(col)\n",
    "    fill_val = -1 if train_df[col].dtype == \"int64\" else \"nan\"\n",
    "    if col == target_col[0]:\n",
    "        train_label_encoders[col].fit(train_df[col].fillna(fill_val))\n",
    "\n",
    "    else: train_label_encoders[col].fit(train_df[col].append(test_df[col]).fillna(fill_val))\n",
    "\n",
    "\n",
    "def train_encode_cat_cols(x, col, tpe):\n",
    "\n",
    "    if pd.isnull(x): \n",
    "        if tpe == \"object\": x = str(x)\n",
    "        elif x == \"int64\": x = 0\n",
    "        \n",
    "    return train_label_encoders[col].transform([x])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/ashutosh/miniconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py\u001b[0m(117)\u001b[0;36m_encode\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    115 \u001b[0;31m            types = sorted(t.__qualname__\n",
      "\u001b[0m\u001b[0;32m    116 \u001b[0;31m                           for t in set(type(v) for v in values))\n",
      "\u001b[0m\u001b[0;32m--> 117 \u001b[0;31m            raise TypeError(\"Encoders require their input to be uniformly \"\n",
      "\u001b[0m\u001b[0;32m    118 \u001b[0;31m                            f\"strings or numbers. Got {types}\")\n",
      "\u001b[0m\u001b[0;32m    119 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> up\n",
      "> \u001b[0;32m/home/ashutosh/miniconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py\u001b[0m(240)\u001b[0;36mfit\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    238 \u001b[0;31m        \"\"\"\n",
      "\u001b[0m\u001b[0;32m    239 \u001b[0;31m        \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 240 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    241 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    242 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> up\n",
      "> \u001b[0;32m<ipython-input-17-3787544f539d>\u001b[0m(18)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     16 \u001b[0;31m        \u001b[0mtrain_label_encoders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     17 \u001b[0;31m    \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 18 \u001b[0;31m    \u001b[0mtrain_label_encoders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nan\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     19 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     20 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> col\n",
      "'ManufacturerID'\n",
      "ipdb> train_df[col].append(test_df[col]).fillna(\"nan\").dtype\n",
      "dtype('O')\n",
      "ipdb> train_df.ManufacturerID\n",
      "0         1568\n",
      "1         1062\n",
      "2         1060\n",
      "3         1060\n",
      "4         1046\n",
      "          ... \n",
      "128650    1568\n",
      "128651    1568\n",
      "128652    1568\n",
      "128653    1568\n",
      "128654    1568\n",
      "Name: ManufacturerID, Length: 128655, dtype: int64\n",
      "ipdb> exit\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_training_data(row):\n",
    "    ret = []\n",
    "    columns = ['ID', 'Frequency', 'InstlmentMode', 'LoanStatus', 'PaymentMode',\n",
    "       'BranchID', 'Area', 'Tenure', 'AssetCost', 'AmountFinance',\n",
    "       'DisbursalAmount', 'EMI', 'DisbursalDate', 'MaturityDAte', 'AuthDate',\n",
    "       'AssetID', 'ManufacturerID', 'SupplierID', 'LTV', 'SEX', 'AGE',\n",
    "       'MonthlyIncome', 'City', 'State', 'ZiPCODE']\n",
    "    column_tpes = []\n",
    "    \n",
    "    for index in range(len(columns)):\n",
    "        if columns[index] in train_cat_cols:\n",
    "            ret.extend(train_encode_cat_cols(row[col], column_tpes[index]))\n",
    "\n",
    "        elif columns[index] in train_reg_cols:\n",
    "        ret.append(encode_reg_cols(row[col]))\n",
    "\n",
    "        elif columns[index] in train_date_cols:\n",
    "            ret.extend(encode_date_cols(row[col]))\n",
    "        else pass\n",
    "    return np.array(ret)\n",
    "    \n",
    "def generate_datasets_to_train(train_dframe, bureau_df, val_size=.2):\n",
    "    ids = train_dframe[\"ID\"].unique()\n",
    "    np.random.shuffle(ids)\n",
    "    sp = int((1. - val_size) * ids.shape[0])\n",
    "    tr_ids, val_ids = ids[: sp], ids[sp:]\n",
    "    X_br, X_val_br = [], []\n",
    "    X, X_val = [], []\n",
    "    y, y_val = [], []\n",
    "    for i in tqdm(tr_ids):\n",
    "        X_br.append(encode_df_for_user(bureau_df[bureau_df.ID == i]))\n",
    "        X.append(generate_training_data(train_dframe[train_dframe.ID == i].values))\n",
    "        y.append(train_dframe[train_dframe.ID == i][target_col].values)\n",
    "        \n",
    "    for i in tqdm(val_ids):\n",
    "        X_val_br.append(encode_df_for_user(bureau_df.ID == i))\n",
    "        \n",
    "        X_val.append(generate_training_data(train_dframe[train_dframe.ID == i].values))\n",
    "        y_val.append(train_dframe[train_dframe.ID == i][target_col].values)\n",
    "    \n",
    "    \n",
    "    return np.array(X), np.array(X_val), np.array(X_br), np.array(X_val_br), np.array(y), np.array(y_val)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = generate_datasets_to_train(train_df.sample(100), df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z[0].shape, z[1].shape, z[2].shape, z[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "#     monitor='val_loss', min_delta=1e-2, patience=5, verbose=0, mode='auto',\n",
    "#     baseline=None, restore_best_weights=True)\n",
    "\n",
    "\n",
    "# # make changes to this and use last dense layer to be target variable.\n",
    "# model = keras.Sequential()\n",
    "# model.add(keras.layers.LSTM(64, kernel_initializer='he_uniform', batch_input_shape=(None, max_window, 205), return_sequences=True, name='encoder_1'))\n",
    "# model.add(keras.layers.LSTM(32, kernel_initializer='he_uniform', return_sequences=True, name='encoder_2'))\n",
    "# model.add(keras.layers.LSTM(16, kernel_initializer='he_uniform', return_sequences=False, name='encoder_3'))\n",
    "# model.add(keras.layers.RepeatVector(max_window, name='encoder_decoder_bridge'))\n",
    "# model.add(keras.layers.LSTM(16, kernel_initializer='he_uniform', return_sequences=True, name='decoder_1'))\n",
    "# model.add(keras.layers.LSTM(32, kernel_initializer='he_uniform', return_sequences=True, name='decoder_2'))\n",
    "# model.add(keras.layers.LSTM(64, kernel_initializer='he_uniform', return_sequences=True, name='decoder_3'))\n",
    "# model.add(keras.layers.TimeDistributed(keras.layers.Dense(205)))\n",
    "# model.compile(loss=\"mse\",optimizer='adam')\n",
    "# # model.build()\n",
    "# print(model.summary())\n",
    "\n",
    "\n",
    "# model.fit(x=z[0], y=z[0], validation_data=(z[1], z[1]), epochs=10, batch_size=batch_size, shuffle=True, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
