{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SELF-INDICATOR</th>\n",
       "      <th>MATCH-TYPE</th>\n",
       "      <th>ACCT-TYPE</th>\n",
       "      <th>CONTRIBUTOR-TYPE</th>\n",
       "      <th>DATE-REPORTED</th>\n",
       "      <th>OWNERSHIP-IND</th>\n",
       "      <th>ACCOUNT-STATUS</th>\n",
       "      <th>DISBURSED-DT</th>\n",
       "      <th>CLOSE-DT</th>\n",
       "      <th>...</th>\n",
       "      <th>OVERDUE-AMT</th>\n",
       "      <th>WRITE-OFF-AMT</th>\n",
       "      <th>ASSET_CLASS</th>\n",
       "      <th>REPORTED DATE - HIST</th>\n",
       "      <th>DPD - HIST</th>\n",
       "      <th>CUR BAL - HIST</th>\n",
       "      <th>AMT OVERDUE - HIST</th>\n",
       "      <th>AMT PAID - HIST</th>\n",
       "      <th>TENURE</th>\n",
       "      <th>INSTALLMENT-TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>PRIMARY</td>\n",
       "      <td>Overdraft</td>\n",
       "      <td>NAB</td>\n",
       "      <td>2018-04-30</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Delinquent</td>\n",
       "      <td>2015-10-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>37873.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Standard</td>\n",
       "      <td>20180430,20180331,</td>\n",
       "      <td>030000</td>\n",
       "      <td>37873,12820,</td>\n",
       "      <td>37873,,</td>\n",
       "      <td>,,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>PRIMARY</td>\n",
       "      <td>Auto Loan (Personal)</td>\n",
       "      <td>NAB</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Active</td>\n",
       "      <td>2018-03-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Standard</td>\n",
       "      <td>20191231,20191130,20191031,20190930,20190831,2...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>20797,21988,23174,24341,25504,26648,27780,2891...</td>\n",
       "      <td>,,,,,,,,,,,,,,,,,,,,1452,,</td>\n",
       "      <td>,,,,,,,,,,,,,,,,,,,,,,</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Monthly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>PRIMARY</td>\n",
       "      <td>Tractor Loan</td>\n",
       "      <td>NBF</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Active</td>\n",
       "      <td>2019-08-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20200131,20191231,20191130,20191031,20190930,2...</td>\n",
       "      <td>000000000000000000</td>\n",
       "      <td>116087,116087,145000,145000,145000,145000,</td>\n",
       "      <td>0,0,0,0,0,0,</td>\n",
       "      <td>,,,,,,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>PRIMARY</td>\n",
       "      <td>Auto Loan (Personal)</td>\n",
       "      <td>NBF</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2013-09-27</td>\n",
       "      <td>2017-09-21</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20170930,20170801,20170731,20170630,20170531,2...</td>\n",
       "      <td>000DDD0270260270260270240270270000320000000000...</td>\n",
       "      <td>0,,15925,23754,31494,39147,46713,54194,61590,6...</td>\n",
       "      <td>0,,1014,1014,1014,1014,1014,1014,1014,983,0,92...</td>\n",
       "      <td>,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>PRIMARY</td>\n",
       "      <td>Tractor Loan</td>\n",
       "      <td>NBF</td>\n",
       "      <td>2016-02-29</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2012-02-10</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160229,20160131,20151231,20151130,20151031,2...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0,0,23658,23321,22989,46321,45662,45012,68030,...</td>\n",
       "      <td>0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...</td>\n",
       "      <td>,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  SELF-INDICATOR MATCH-TYPE             ACCT-TYPE CONTRIBUTOR-TYPE  \\\n",
       "0   1           False    PRIMARY             Overdraft              NAB   \n",
       "1   1           False    PRIMARY  Auto Loan (Personal)              NAB   \n",
       "2   1            True    PRIMARY          Tractor Loan              NBF   \n",
       "3   1            True    PRIMARY  Auto Loan (Personal)              NBF   \n",
       "4   1            True    PRIMARY          Tractor Loan              NBF   \n",
       "\n",
       "  DATE-REPORTED OWNERSHIP-IND ACCOUNT-STATUS DISBURSED-DT    CLOSE-DT  ...  \\\n",
       "0    2018-04-30    Individual     Delinquent   2015-10-05         NaN  ...   \n",
       "1    2019-12-31    Individual         Active   2018-03-19         NaN  ...   \n",
       "2    2020-01-31    Individual         Active   2019-08-30         NaN  ...   \n",
       "3    2017-09-30    Individual         Closed   2013-09-27  2017-09-21  ...   \n",
       "4    2016-02-29    Individual         Closed   2012-02-10  2016-02-01  ...   \n",
       "\n",
       "  OVERDUE-AMT  WRITE-OFF-AMT  ASSET_CLASS  \\\n",
       "0     37873.0            0.0     Standard   \n",
       "1         NaN            0.0     Standard   \n",
       "2         0.0            0.0          NaN   \n",
       "3         0.0            0.0          NaN   \n",
       "4         0.0            0.0          NaN   \n",
       "\n",
       "                                REPORTED DATE - HIST  \\\n",
       "0                                 20180430,20180331,   \n",
       "1  20191231,20191130,20191031,20190930,20190831,2...   \n",
       "2  20200131,20191231,20191130,20191031,20190930,2...   \n",
       "3  20170930,20170801,20170731,20170630,20170531,2...   \n",
       "4  20160229,20160131,20151231,20151130,20151031,2...   \n",
       "\n",
       "                                          DPD - HIST  \\\n",
       "0                                             030000   \n",
       "1  0000000000000000000000000000000000000000000000...   \n",
       "2                                 000000000000000000   \n",
       "3  000DDD0270260270260270240270270000320000000000...   \n",
       "4  0000000000000000000000000000000000000000000000...   \n",
       "\n",
       "                                      CUR BAL - HIST  \\\n",
       "0                                       37873,12820,   \n",
       "1  20797,21988,23174,24341,25504,26648,27780,2891...   \n",
       "2         116087,116087,145000,145000,145000,145000,   \n",
       "3  0,,15925,23754,31494,39147,46713,54194,61590,6...   \n",
       "4  0,0,23658,23321,22989,46321,45662,45012,68030,...   \n",
       "\n",
       "                                  AMT OVERDUE - HIST  \\\n",
       "0                                            37873,,   \n",
       "1                         ,,,,,,,,,,,,,,,,,,,,1452,,   \n",
       "2                                       0,0,0,0,0,0,   \n",
       "3  0,,1014,1014,1014,1014,1014,1014,1014,983,0,92...   \n",
       "4  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...   \n",
       "\n",
       "                         AMT PAID - HIST TENURE INSTALLMENT-TYPE  \n",
       "0                                     ,,    NaN              NaN  \n",
       "1                 ,,,,,,,,,,,,,,,,,,,,,,   36.0          Monthly  \n",
       "2                                 ,,,,,,    NaN              NaN  \n",
       "3  ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,    NaN              NaN  \n",
       "4  ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,    NaN              NaN  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow import keras\n",
    "import os, logging\n",
    "import tensorflow as tf\n",
    "from tqdm.notebook import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import pickle as pkl\n",
    "from tensorflow.keras.layers import LSTM, Dense, TimeDistributed, Embedding, Bidirectional, Dropout, concatenate, SpatialDropout1D, GlobalMaxPooling1D, Reshape, MaxPooling1D, Flatten, Conv1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import Input\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "df = pd.read_csv(\"Train/cleaned_bureau.csv\")\n",
    "tdf = pd.read_csv(\"Test/cleaned_bureau.csv\")\n",
    "train_df = pd.read_csv(\"Train/cleaned_train.csv\")\n",
    "test_df = pd.read_csv(\"Test/cleaned_train.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71060     420\n",
       " 141732    165\n",
       " 51786     152\n",
       " 1167      138\n",
       " 97794     124\n",
       "          ... \n",
       " 107223      1\n",
       " 109270      1\n",
       " 116205      1\n",
       " 103121      1\n",
       " 9436        1\n",
       " Name: ID, Length: 128655, dtype: int64,\n",
       " (64019, 26))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ID.value_counts(sort=True, ascending=False), tdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114111    93\n",
       "114063    60\n",
       "69953     59\n",
       "26305     59\n",
       "114125    56\n",
       "          ..\n",
       "78473      1\n",
       "141962     1\n",
       "62097      1\n",
       "141994     1\n",
       "98272      1\n",
       "Name: ID, Length: 14745, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdf.ID.value_counts(sort=True, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['SELF-INDICATOR', 'MATCH-TYPE', 'ACCT-TYPE', 'CONTRIBUTOR-TYPE',\n",
    "       'OWNERSHIP-IND', 'ACCOUNT-STATUS', 'INSTALLMENT-TYPE',\n",
    "       'ASSET_CLASS', 'INSTALLMENT-FREQUENCY',\n",
    "       'DPD - HIST']    #should not be here\n",
    "date_cols = ['DATE-REPORTED',  'DISBURSED-DT', 'CLOSE-DT', \n",
    "             'LAST-PAYMENT-DATE']\n",
    "reg_cols = ['CREDIT-LIMIT/SANC AMT', 'DISBURSED-AMT/HIGH CREDIT', 'INSTALLMENT-AMT', 'CURRENT-BAL',\n",
    "        'OVERDUE-AMT', 'WRITE-OFF-AMT', 'TENURE'] # , 'DPD - HIST']\n",
    "array_cols = ['REPORTED DATE - HIST', 'CUR BAL - HIST',\n",
    "       'AMT OVERDUE - HIST', 'AMT PAID - HIST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, (560844, 26))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat_cols) + len(date_cols) + len(reg_cols) + len(array_cols), df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all([df[i].dtype in (\"bool\" ,\"object\") for i in cat_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all([df[i].dtype == \"float64\" for i in reg_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATE-REPORTED          3683\n",
       "DISBURSED-DT          32150\n",
       "CLOSE-DT             251827\n",
       "LAST-PAYMENT-DATE    319283\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[date_cols].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATE-REPORTED          3683\n",
       "DISBURSED-DT          32150\n",
       "CLOSE-DT             251827\n",
       "LAST-PAYMENT-DATE    319283\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in date_cols:\n",
    "    df[col] = pd.to_datetime(df[col])\n",
    "    tdf[col] = pd.to_datetime(tdf[col])\n",
    "df[date_cols].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max train 37.0\n",
      "max test 37.0\n",
      "max train 37.0\n",
      "max test 37.0\n",
      "max train 42.0\n",
      "max test 37.0\n",
      "max train 38.0\n",
      "max test 38.0\n"
     ]
    }
   ],
   "source": [
    "def get_length(amt):    \n",
    "    if not pd.isnull(amt):\n",
    "        return len(amt.split(\",\"))\n",
    "    else: 0\n",
    "        \n",
    "for col in array_cols:\n",
    "    print(\"max train {}\".format(df[col].apply(lambda x: get_length(x)).max()))\n",
    "    \n",
    "    print(\"max test {}\".format(tdf[col].apply(lambda x: get_length(x)).max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_window = 420\n",
    "ts_feature_vector = 205\n",
    "max_array_size = 42\n",
    "label_encoder_dict = {}\n",
    "num_cores = 7\n",
    "\n",
    "def encode_reg_cols(x):\n",
    "    if pd.isnull(x):\n",
    "        return 0.\n",
    "    return np.float64(x)\n",
    "\n",
    "def encode_array_cols(x):\n",
    "    ret = [0] * max_array_size\n",
    "    if not pd.isnull(x):\n",
    "        l = x.split(\",\")\n",
    "        y = max_array_size - len(l)\n",
    "        for index in range(len(l)):\n",
    "            try:\n",
    "                ret[y + index] = np.float32(l[index])\n",
    "            except:\n",
    "                ret[y + index] = 0.\n",
    "    return ret\n",
    "\n",
    "\n",
    "def encode_date_cols(x):\n",
    "    if pd.isnull(x):\n",
    "        return [-1., -1., -1., -1., -1.]\n",
    "    else:\n",
    "        return np.array([x.hour, x.minute, x.day, x.month, x.year], dtype=np.float64)\n",
    "\n",
    "\n",
    "def encode_cat_cols(x, col):\n",
    "\n",
    "    if pd.isnull(x): x = str(x)\n",
    "    return np.array(label_encoder_dict[col].transform([x]), dtype=np.float64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5711c5564ff74439b9f686a758210a81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELF-INDICATOR\n",
      "MATCH-TYPE\n",
      "ACCT-TYPE\n",
      "CONTRIBUTOR-TYPE\n",
      "OWNERSHIP-IND\n",
      "ACCOUNT-STATUS\n",
      "INSTALLMENT-TYPE\n",
      "ASSET_CLASS\n",
      "INSTALLMENT-FREQUENCY\n",
      "DPD - HIST\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for col in tqdm(cat_cols):\n",
    "    if col not in label_encoder_dict:\n",
    "        label_encoder_dict[col] = LabelEncoder()\n",
    "    print(col)\n",
    "    label_encoder_dict[col].fit(df[col].append(tdf[col]).fillna(\"nan\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_df = df[df.ID == 141732]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_df_for_user(dframe):\n",
    "    \n",
    "    final = []\n",
    "    for index, row in dframe.iterrows():\n",
    "        \n",
    "        l = [None] * 4\n",
    "        ret = np.array([], dtype=np.float64)\n",
    "    \n",
    "        # 10 * 1\n",
    "        for col in cat_cols:\n",
    "            ret = np.concatenate((ret, encode_cat_cols(row[col], col)))\n",
    "        \n",
    "        # 7 * 1 = 7\n",
    "        for col in reg_cols:\n",
    "            ret = np.concatenate((ret, np.array([encode_reg_cols(row[col])])))\n",
    "        \n",
    "        # 5 * 4 = 20\n",
    "        for col in date_cols:\n",
    "            ret = np.concatenate((ret, encode_date_cols(row[col])))\n",
    "        \n",
    "        # 4 * 42 = 168\n",
    "        for i in range(4):\n",
    "            l[i] = encode_array_cols(array_cols[i])\n",
    "            \n",
    "        \n",
    "        ret = np.concatenate((ret, np.array(tf.keras.preprocessing.sequence.pad_sequences(l, maxlen=max_array_size, padding='pre')).flatten()))\n",
    "        assert len(ret) == ts_feature_vector, print(len(l), len(l[0]))\n",
    "        final.append(ret)\n",
    "    while len(final) < max_window:\n",
    "        final.insert(0, [0.] * ts_feature_vector)\n",
    "    return np.array(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode_df_for_user(temp_df).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c0837fb8451476e9eeb3849975780c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency\n",
      "InstlmentMode\n",
      "LoanStatus\n",
      "PaymentMode\n",
      "BranchID\n",
      "Area\n",
      "ManufacturerID\n",
      "SupplierID\n",
      "SEX\n",
      "City\n",
      "State\n",
      "ZiPCODE\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashutosh/miniconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_label_encoders = {}\n",
    "target_encoder = LabelEncoder()\n",
    "\n",
    "\n",
    "\n",
    "train_cat_cols = ['Frequency', 'InstlmentMode', 'LoanStatus', 'PaymentMode', 'BranchID', 'Area', \n",
    "            'ManufacturerID', 'SupplierID', 'SEX', 'City', 'State', 'ZiPCODE']\n",
    "target_col = ['Top-up Month']\n",
    "train_reg_cols = ['AmountFinance', 'DisbursalAmount', 'EMI', 'AssetID', 'MonthlyIncome', 'Tenure', 'AssetCost', 'LTV', 'AGE']\n",
    "train_date_cols = ['DisbursalDate', 'MaturityDAte', 'AuthDate']\n",
    "\n",
    "for col in train_date_cols:\n",
    "    train_df[col] = pd.to_datetime(train_df[col], errors=\"coerce\")\n",
    "    test_df[col] = pd.to_datetime(test_df[col], errors=\"coerce\")\n",
    "    \n",
    "for col in tqdm(train_cat_cols):\n",
    "    if col not in train_label_encoders:\n",
    "        train_label_encoders[col] = LabelEncoder()\n",
    "    print(col)\n",
    "    fill_val = -1 if train_df[col].dtype == \"int64\" else \"nan\"\n",
    "    if col == target_col[0]:\n",
    "        train_label_encoders[col].fit(train_df[col].fillna(fill_val))\n",
    "\n",
    "    else: train_label_encoders[col].fit(train_df[col].append(test_df[col]).fillna(fill_val))\n",
    "\n",
    "target_encoder.fit(train_df[target_col])\n",
    "\n",
    "def train_encode_cat_cols(x, col, tpe):\n",
    "\n",
    "    if pd.isnull(x): \n",
    "        if tpe == \"object\": x = str(x)\n",
    "        elif x == \"int64\": x = 0\n",
    "        else: assert False\n",
    "        \n",
    "    return train_label_encoders[col].transform([x])   \n",
    "\n",
    "def encode_target(x):\n",
    "    return target_encoder.transform(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_max_len = 36\n",
    "def generate_training_data(row):\n",
    "    row = row[0]\n",
    "    ret = []\n",
    "    columns = ['ID', 'Frequency', 'InstlmentMode', 'LoanStatus', 'PaymentMode',\n",
    "       'BranchID', 'Area', 'Tenure', 'AssetCost', 'AmountFinance',\n",
    "       'DisbursalAmount', 'EMI', 'DisbursalDate', 'MaturityDAte', 'AuthDate',\n",
    "       'AssetID', 'ManufacturerID', 'SupplierID', 'LTV', 'SEX', 'AGE',\n",
    "       'MonthlyIncome', 'City', 'State', 'ZiPCODE']\n",
    "    column_tpes = ['int64', 'object', 'object', 'object', 'object', \n",
    "                   'int64', 'object', 'int64', 'int64','float64', \n",
    "                   'float64', 'float64',  '<M8[ns]', '<M8[ns]', '<M8[ns]',\n",
    "                   'int64', 'int64', 'int64', 'float64', 'object', \n",
    "                   'float64', 'float64', 'object', 'object', 'int64', 'object']\n",
    "    \n",
    "    for index in range(len(columns)):\n",
    "        if columns[index] in train_cat_cols:\n",
    "            \n",
    "            ret.extend(train_encode_cat_cols(row[index], columns[index], column_tpes[index]))\n",
    "\n",
    "        elif columns[index] in train_reg_cols:\n",
    "            ret.append(encode_reg_cols(row[index]))\n",
    "\n",
    "        elif columns[index] in train_date_cols:\n",
    "            ret.extend(encode_date_cols(row[index]))\n",
    "        else: pass\n",
    "    return np.array(ret)\n",
    "    \n",
    "def generate_datasets_to_train(train_dframe, bureau_df, val_size=.2):\n",
    "    ids = train_dframe[\"ID\"].unique()\n",
    "    np.random.shuffle(ids)\n",
    "    sp = int((1. - val_size) * ids.shape[0])\n",
    "    tr_ids, val_ids = ids[: sp], ids[sp:]\n",
    "    y, y_val = [], []\n",
    "    \n",
    "    \n",
    "    X = Parallel(n_jobs=num_cores)(delayed(generate_training_data)(train_dframe[train_dframe.ID == i].to_numpy()) for i in tqdm(tr_ids, total=len(tr_ids)))\n",
    "    X_br = Parallel(n_jobs=num_cores)(delayed(encode_df_for_user)(bureau_df[bureau_df.ID == i]) for i in tqdm(tr_ids, total=len(tr_ids)))\n",
    "    \n",
    "    X_val = Parallel(n_jobs=num_cores)(delayed(generate_training_data)(train_dframe[train_dframe.ID == i].to_numpy()) for i in tqdm(val_ids, total=len(val_ids)))\n",
    "    X_val_br = Parallel(n_jobs=num_cores)(delayed(encode_df_for_user)(bureau_df[bureau_df.ID == i]) for i in tqdm(val_ids, total=len(val_ids)))\n",
    "    \n",
    "\n",
    "    for i in tqdm(tr_ids):\n",
    "        y.append(target_encoder.transform(train_dframe[train_dframe.ID == i][target_col].values))\n",
    "        \n",
    "    for i in tqdm(val_ids):\n",
    "        y_val.append(target_encoder.transform(train_dframe[train_dframe.ID == i][target_col].values))\n",
    "    return np.array(X), np.array(X_val), np.array(X_br), np.array(X_val_br), np.array(y), np.array(y_val)\n",
    "    \n",
    "\n",
    "def generate_datasets_to_train_for_one_user(train_dframe, bureau_df):\n",
    "    \n",
    "    X_br = []\n",
    "    X = []\n",
    "    \n",
    "    X_br.append(encode_df_for_user(bureau_df))\n",
    "    X.append(generate_training_data(train_dframe.to_numpy()))\n",
    "    return np.array(X), np.array(X_br)\n",
    "    \n",
    "def generate_datasets_to_train_for_one_user_test(train_dframe, bureau_df):\n",
    "    \n",
    "    X_br =  []\n",
    "    X = []\n",
    "    X_br.append(encode_df_for_user(bureau_df))\n",
    "    X.append(generate_training_data(train_dframe.to_numpy()))\n",
    "    return np.array(X), np.array(X_br)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, list_ids, bs=batch_size, test=False):\n",
    "        self.bs = bs\n",
    "        self.list_ids = list_ids\n",
    "        self.n_classes = 7\n",
    "        self.shuffle = False if test else True\n",
    "        self.test = test\n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.list_ids) / self.bs))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        idx_min = index * self.bs\n",
    "        idx_max = min(idx_min + self.bs, len(self.list_ids))\n",
    "        indexes = self.indexes[idx_min: idx_max]\n",
    "        \n",
    "        temp_list_ids = [self.list_ids[k] for k in indexes]\n",
    "        if self.test:\n",
    "            X = self.__data_generator(temp_list_ids)\n",
    "            return X\n",
    "        else:\n",
    "            X, y = self.__data_generator(temp_list_ids)\n",
    "            return X, y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.list_ids))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "            \n",
    "    def __data_generator(self, temp_list):\n",
    "        X = [None] * len(temp_list)\n",
    "        y = [None] * len(temp_list)\n",
    "        for index in range(len(temp_list)):\n",
    "            i = temp_list[index]\n",
    "            if self.test:\n",
    "                X[index] = generate_datasets_to_train_for_one_user_test(\n",
    "                    test_df[test_df.ID == i],\n",
    "                    tdf[tdf.ID == i]\n",
    "                )\n",
    "            else:\n",
    "                X[index] = generate_datasets_to_train_for_one_user(\n",
    "                    train_df[train_df.ID == i],\n",
    "                    df[df.ID == i]\n",
    "                )\n",
    "                \n",
    "                y[index] = train_df[train_df.ID == i][target_col].values[0]\n",
    "                \n",
    "        if self.test:\n",
    "            return X\n",
    "\n",
    "        y = target_encoder.transform(y)\n",
    "        return X, keras.utils.to_categorical(y, num_classes=self.n_classes)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return 1 - K.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 420, 205)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 420, 128)     171008      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 36)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 420, 64)      49408       lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 32)           1184        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 420, 36)      14544       lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 15120)        0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 15152)        0           dropout[0][0]                    \n",
      "                                                                 reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 15152)        0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           484896      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 7)            231         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 721,271\n",
      "Trainable params: 721,271\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    train_in = Input(shape=(train_max_len, ))\n",
    "    train_int = Dense(32,activation=\"relu\")(train_in)\n",
    "    train_int = Dropout(.2, seed=42)(train_int)\n",
    "    bureau_in = Input(shape=(max_window, ts_feature_vector))\n",
    "    bureau_int = LSTM(128, kernel_initializer='he_uniform', return_sequences=True)(bureau_in)\n",
    "    bureau_int = LSTM(64, kernel_initializer='he_uniform', return_sequences=True)(bureau_int)\n",
    "    bureau_int = LSTM(36, kernel_initializer='he_uniform', return_sequences=True)(bureau_int)\n",
    "    bureau_int = Reshape((420*36,), input_shape=(None, 420, 36))(bureau_int)\n",
    "    x = concatenate([train_int, bureau_int])\n",
    "    x = Dropout(.2, seed=42)(x)\n",
    "    \n",
    "    x = Dense(32,activation=\"relu\")(x)\n",
    "    output = Dense(7, activation=\"softmax\")(x)\n",
    "    model = Model([train_in, bureau_in], output)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        loss=f1_loss,\n",
    "        metrics=[\"acc\", f1_loss],\n",
    "    )\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = .2\n",
    "ids = train_df[\"ID\"].head(10000).unique()\n",
    "np.random.shuffle(ids)\n",
    "sp = int((1. - val_size) * ids.shape[0])\n",
    "tr_ids, val_ids = ids[: sp], ids[sp:]\n",
    "test_ids = test_df[\"ID\"].head(100).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = DataGenerator(tr_ids, bs=batch_size)\n",
    "val_gen = DataGenerator(val_ids)\n",
    "test_gen = DataGenerator(test_ids, test=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      " 39/250 [===>..........................] - ETA: 53:18 - loss: 0.9338 - acc: 0.4062 - f1_loss: 0.9338"
     ]
    }
   ],
   "source": [
    "model.fit_generator(generator=train_gen, validation_data=val_gen, \n",
    "                    epochs=2,\n",
    "                   use_multiprocessing=True, workers=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_save/model.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(test_gen, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('model_save/model.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
