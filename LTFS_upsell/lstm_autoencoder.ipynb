{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SELF-INDICATOR</th>\n",
       "      <th>MATCH-TYPE</th>\n",
       "      <th>ACCT-TYPE</th>\n",
       "      <th>CONTRIBUTOR-TYPE</th>\n",
       "      <th>DATE-REPORTED</th>\n",
       "      <th>OWNERSHIP-IND</th>\n",
       "      <th>ACCOUNT-STATUS</th>\n",
       "      <th>DISBURSED-DT</th>\n",
       "      <th>CLOSE-DT</th>\n",
       "      <th>...</th>\n",
       "      <th>OVERDUE-AMT</th>\n",
       "      <th>WRITE-OFF-AMT</th>\n",
       "      <th>ASSET_CLASS</th>\n",
       "      <th>REPORTED DATE - HIST</th>\n",
       "      <th>DPD - HIST</th>\n",
       "      <th>CUR BAL - HIST</th>\n",
       "      <th>AMT OVERDUE - HIST</th>\n",
       "      <th>AMT PAID - HIST</th>\n",
       "      <th>TENURE</th>\n",
       "      <th>INSTALLMENT-TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>PRIMARY</td>\n",
       "      <td>Overdraft</td>\n",
       "      <td>NAB</td>\n",
       "      <td>2018-04-30</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Delinquent</td>\n",
       "      <td>2015-10-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>37873.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Standard</td>\n",
       "      <td>20180430,20180331,</td>\n",
       "      <td>030000</td>\n",
       "      <td>37873,12820,</td>\n",
       "      <td>37873,,</td>\n",
       "      <td>,,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>PRIMARY</td>\n",
       "      <td>Auto Loan (Personal)</td>\n",
       "      <td>NAB</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Active</td>\n",
       "      <td>2018-03-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Standard</td>\n",
       "      <td>20191231,20191130,20191031,20190930,20190831,2...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>20797,21988,23174,24341,25504,26648,27780,2891...</td>\n",
       "      <td>,,,,,,,,,,,,,,,,,,,,1452,,</td>\n",
       "      <td>,,,,,,,,,,,,,,,,,,,,,,</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Monthly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>PRIMARY</td>\n",
       "      <td>Tractor Loan</td>\n",
       "      <td>NBF</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Active</td>\n",
       "      <td>2019-08-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20200131,20191231,20191130,20191031,20190930,2...</td>\n",
       "      <td>000000000000000000</td>\n",
       "      <td>116087,116087,145000,145000,145000,145000,</td>\n",
       "      <td>0,0,0,0,0,0,</td>\n",
       "      <td>,,,,,,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>PRIMARY</td>\n",
       "      <td>Auto Loan (Personal)</td>\n",
       "      <td>NBF</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2013-09-27</td>\n",
       "      <td>2017-09-21</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20170930,20170801,20170731,20170630,20170531,2...</td>\n",
       "      <td>000DDD0270260270260270240270270000320000000000...</td>\n",
       "      <td>0,,15925,23754,31494,39147,46713,54194,61590,6...</td>\n",
       "      <td>0,,1014,1014,1014,1014,1014,1014,1014,983,0,92...</td>\n",
       "      <td>,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>PRIMARY</td>\n",
       "      <td>Tractor Loan</td>\n",
       "      <td>NBF</td>\n",
       "      <td>2016-02-29</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2012-02-10</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160229,20160131,20151231,20151130,20151031,2...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0,0,23658,23321,22989,46321,45662,45012,68030,...</td>\n",
       "      <td>0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...</td>\n",
       "      <td>,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  SELF-INDICATOR MATCH-TYPE             ACCT-TYPE CONTRIBUTOR-TYPE  \\\n",
       "0   1           False    PRIMARY             Overdraft              NAB   \n",
       "1   1           False    PRIMARY  Auto Loan (Personal)              NAB   \n",
       "2   1            True    PRIMARY          Tractor Loan              NBF   \n",
       "3   1            True    PRIMARY  Auto Loan (Personal)              NBF   \n",
       "4   1            True    PRIMARY          Tractor Loan              NBF   \n",
       "\n",
       "  DATE-REPORTED OWNERSHIP-IND ACCOUNT-STATUS DISBURSED-DT    CLOSE-DT  ...  \\\n",
       "0    2018-04-30    Individual     Delinquent   2015-10-05         NaN  ...   \n",
       "1    2019-12-31    Individual         Active   2018-03-19         NaN  ...   \n",
       "2    2020-01-31    Individual         Active   2019-08-30         NaN  ...   \n",
       "3    2017-09-30    Individual         Closed   2013-09-27  2017-09-21  ...   \n",
       "4    2016-02-29    Individual         Closed   2012-02-10  2016-02-01  ...   \n",
       "\n",
       "  OVERDUE-AMT  WRITE-OFF-AMT  ASSET_CLASS  \\\n",
       "0     37873.0            0.0     Standard   \n",
       "1         NaN            0.0     Standard   \n",
       "2         0.0            0.0          NaN   \n",
       "3         0.0            0.0          NaN   \n",
       "4         0.0            0.0          NaN   \n",
       "\n",
       "                                REPORTED DATE - HIST  \\\n",
       "0                                 20180430,20180331,   \n",
       "1  20191231,20191130,20191031,20190930,20190831,2...   \n",
       "2  20200131,20191231,20191130,20191031,20190930,2...   \n",
       "3  20170930,20170801,20170731,20170630,20170531,2...   \n",
       "4  20160229,20160131,20151231,20151130,20151031,2...   \n",
       "\n",
       "                                          DPD - HIST  \\\n",
       "0                                             030000   \n",
       "1  0000000000000000000000000000000000000000000000...   \n",
       "2                                 000000000000000000   \n",
       "3  000DDD0270260270260270240270270000320000000000...   \n",
       "4  0000000000000000000000000000000000000000000000...   \n",
       "\n",
       "                                      CUR BAL - HIST  \\\n",
       "0                                       37873,12820,   \n",
       "1  20797,21988,23174,24341,25504,26648,27780,2891...   \n",
       "2         116087,116087,145000,145000,145000,145000,   \n",
       "3  0,,15925,23754,31494,39147,46713,54194,61590,6...   \n",
       "4  0,0,23658,23321,22989,46321,45662,45012,68030,...   \n",
       "\n",
       "                                  AMT OVERDUE - HIST  \\\n",
       "0                                            37873,,   \n",
       "1                         ,,,,,,,,,,,,,,,,,,,,1452,,   \n",
       "2                                       0,0,0,0,0,0,   \n",
       "3  0,,1014,1014,1014,1014,1014,1014,1014,983,0,92...   \n",
       "4  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...   \n",
       "\n",
       "                         AMT PAID - HIST TENURE INSTALLMENT-TYPE  \n",
       "0                                     ,,    NaN              NaN  \n",
       "1                 ,,,,,,,,,,,,,,,,,,,,,,   36.0          Monthly  \n",
       "2                                 ,,,,,,    NaN              NaN  \n",
       "3  ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,    NaN              NaN  \n",
       "4  ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,    NaN              NaN  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tqdm.notebook import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import pickle as pkl\n",
    "from tensorflow.keras.layers import LSTM, Dense, TimeDistributed, Embedding, Bidirectional, Dropout, concatenate, SpatialDropout1D, GlobalMaxPooling1D, Reshape, MaxPooling1D, Flatten, Conv1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "df = pd.read_csv(\"Train/cleaned_bureau.csv\")\n",
    "tdf = pd.read_csv(\"Test/cleaned_bureau.csv\")\n",
    "train_df = pd.read_csv(\"Train/cleaned_train.csv\")\n",
    "test_df = pd.read_csv(\"Test/cleaned_train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71060     420\n",
       "141732    165\n",
       "51786     152\n",
       "1167      138\n",
       "97794     124\n",
       "         ... \n",
       "107223      1\n",
       "109270      1\n",
       "116205      1\n",
       "103121      1\n",
       "9436        1\n",
       "Name: ID, Length: 128655, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ID.value_counts(sort=True, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114111    93\n",
       "114063    60\n",
       "69953     59\n",
       "26305     59\n",
       "114125    56\n",
       "          ..\n",
       "78473      1\n",
       "141962     1\n",
       "62097      1\n",
       "141994     1\n",
       "98272      1\n",
       "Name: ID, Length: 14745, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdf.ID.value_counts(sort=True, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['SELF-INDICATOR', 'MATCH-TYPE', 'ACCT-TYPE', 'CONTRIBUTOR-TYPE',\n",
    "       'OWNERSHIP-IND', 'ACCOUNT-STATUS', 'INSTALLMENT-TYPE',\n",
    "       'ASSET_CLASS', 'INSTALLMENT-FREQUENCY',\n",
    "       'DPD - HIST']    #should not be here\n",
    "date_cols = ['DATE-REPORTED',  'DISBURSED-DT', 'CLOSE-DT', \n",
    "             'LAST-PAYMENT-DATE']\n",
    "reg_cols = ['CREDIT-LIMIT/SANC AMT', 'DISBURSED-AMT/HIGH CREDIT', 'INSTALLMENT-AMT', 'CURRENT-BAL',\n",
    "        'OVERDUE-AMT', 'WRITE-OFF-AMT', 'TENURE'] # , 'DPD - HIST']\n",
    "array_cols = ['REPORTED DATE - HIST', 'CUR BAL - HIST',\n",
    "       'AMT OVERDUE - HIST', 'AMT PAID - HIST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, (560844, 26))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat_cols) + len(date_cols) + len(reg_cols) + len(array_cols), df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all([df[i].dtype in (\"bool\" ,\"object\") for i in cat_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all([df[i].dtype == \"float64\" for i in reg_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATE-REPORTED          3683\n",
       "DISBURSED-DT          32150\n",
       "CLOSE-DT             251827\n",
       "LAST-PAYMENT-DATE    319283\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[date_cols].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATE-REPORTED          3683\n",
       "DISBURSED-DT          32150\n",
       "CLOSE-DT             251827\n",
       "LAST-PAYMENT-DATE    319283\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in date_cols:\n",
    "    df[col] = pd.to_datetime(df[col])\n",
    "    tdf[col] = pd.to_datetime(tdf[col])\n",
    "df[date_cols].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max train 37.0\n",
      "max test 37.0\n",
      "max train 37.0\n",
      "max test 37.0\n",
      "max train 42.0\n",
      "max test 37.0\n",
      "max train 38.0\n",
      "max test 38.0\n"
     ]
    }
   ],
   "source": [
    "def get_length(amt):    \n",
    "    if not pd.isnull(amt):\n",
    "        return len(amt.split(\",\"))\n",
    "    else: 0\n",
    "        \n",
    "for col in array_cols:\n",
    "    print(\"max train {}\".format(df[col].apply(lambda x: get_length(x)).max()))\n",
    "    \n",
    "    print(\"max test {}\".format(tdf[col].apply(lambda x: get_length(x)).max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_window = 420\n",
    "ts_feature_vector = 205\n",
    "max_array_size = 42\n",
    "label_encoder_dict = {}\n",
    "num_cores = 4\n",
    "\n",
    "def encode_reg_cols(x):\n",
    "    if pd.isnull(x):\n",
    "        return 0.\n",
    "    return x\n",
    "\n",
    "def encode_array_cols(x):\n",
    "    if pd.isnull(x):\n",
    "        return [0] * max_array_size\n",
    "    else:\n",
    "        ret = []\n",
    "        for val in x.split(\",\"):\n",
    "            try:\n",
    "                ret.append(float(val))\n",
    "            except:\n",
    "                ret.append(0.)\n",
    "        while len(ret) < max_array_size:\n",
    "            ret.append(0.)\n",
    "        return ret\n",
    "\n",
    "\n",
    "def encode_date_cols(x):\n",
    "    if pd.isnull(x):\n",
    "        return [-1, -1, -1, -1, -1]\n",
    "    else:\n",
    "        return [x.hour, x.minute, x.day, x.month, x.year]\n",
    "\n",
    "\n",
    "def encode_cat_cols(x, col):\n",
    "\n",
    "    if pd.isnull(x): x = str(x)\n",
    "    return label_encoder_dict[col].transform([x])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b86d0af1bb104ce58e982eff7f2e58f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELF-INDICATOR\n",
      "MATCH-TYPE\n",
      "ACCT-TYPE\n",
      "CONTRIBUTOR-TYPE\n",
      "OWNERSHIP-IND\n",
      "ACCOUNT-STATUS\n",
      "INSTALLMENT-TYPE\n",
      "ASSET_CLASS\n",
      "INSTALLMENT-FREQUENCY\n",
      "DPD - HIST\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for col in tqdm(cat_cols):\n",
    "    if col not in label_encoder_dict:\n",
    "        label_encoder_dict[col] = LabelEncoder()\n",
    "    print(col)\n",
    "    label_encoder_dict[col].fit(df[col].append(tdf[col]).fillna(\"nan\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = df[df.ID == 141732]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_df_for_user(dframe):\n",
    "    \n",
    "    final = []\n",
    "    for index, row in dframe.iterrows():\n",
    "        ret = []\n",
    "    \n",
    "        # 10 * 1\n",
    "        for col in cat_cols:\n",
    "            ret.extend(encode_cat_cols(row[col], col))\n",
    "        \n",
    "        # 7 * 1 = 7\n",
    "        for col in reg_cols:\n",
    "            ret.append(encode_reg_cols(row[col]))\n",
    "        \n",
    "        # 5 * 4 = 20\n",
    "        for col in date_cols:\n",
    "            \n",
    "            ret.extend(encode_date_cols(row[col]))\n",
    "        \n",
    "        \n",
    "        # 4 * 42 = 168\n",
    "        for col in array_cols:\n",
    "            ret.extend(encode_array_cols(row[col]))\n",
    "        \n",
    "        assert len(ret) == ts_feature_vector\n",
    "        final.append(ret)\n",
    "    while len(final) < max_window:\n",
    "        final.insert(0, [0.] * ts_feature_vector)\n",
    "    assert len(final) == max_window\n",
    "    return np.array(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(420, 205)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_df_for_user(temp_df).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88e37a783c094972ab1f2fb0956d7022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency\n",
      "InstlmentMode\n",
      "LoanStatus\n",
      "PaymentMode\n",
      "BranchID\n",
      "Area\n",
      "ManufacturerID\n",
      "SupplierID\n",
      "SEX\n",
      "City\n",
      "State\n",
      "ZiPCODE\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashutosh/miniconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_label_encoders = {}\n",
    "target_encoder = LabelEncoder()\n",
    "\n",
    "\n",
    "\n",
    "train_cat_cols = ['Frequency', 'InstlmentMode', 'LoanStatus', 'PaymentMode', 'BranchID', 'Area', \n",
    "            'ManufacturerID', 'SupplierID', 'SEX', 'City', 'State', 'ZiPCODE']\n",
    "target_col = ['Top-up Month']\n",
    "train_reg_cols = ['AmountFinance', 'DisbursalAmount', 'EMI', 'AssetID', 'MonthlyIncome', 'Tenure', 'AssetCost', 'LTV', 'AGE']\n",
    "train_date_cols = ['DisbursalDate', 'MaturityDAte', 'AuthDate']\n",
    "\n",
    "for col in train_date_cols:\n",
    "    train_df[col] = pd.to_datetime(train_df[col], errors=\"coerce\")\n",
    "    test_df[col] = pd.to_datetime(test_df[col], errors=\"coerce\")\n",
    "    \n",
    "for col in tqdm(train_cat_cols):\n",
    "    if col not in train_label_encoders:\n",
    "        train_label_encoders[col] = LabelEncoder()\n",
    "    print(col)\n",
    "    fill_val = -1 if train_df[col].dtype == \"int64\" else \"nan\"\n",
    "    if col == target_col[0]:\n",
    "        train_label_encoders[col].fit(train_df[col].fillna(fill_val))\n",
    "\n",
    "    else: train_label_encoders[col].fit(train_df[col].append(test_df[col]).fillna(fill_val))\n",
    "\n",
    "target_encoder.fit(train_df[target_col])\n",
    "\n",
    "def train_encode_cat_cols(x, col, tpe):\n",
    "\n",
    "    if pd.isnull(x): \n",
    "        if tpe == \"object\": x = str(x)\n",
    "        elif x == \"int64\": x = 0\n",
    "        else: assert False\n",
    "        \n",
    "    return train_label_encoders[col].transform([x])   \n",
    "\n",
    "def encode_target(x):\n",
    "    return target_encoder.transform(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_max_len = 36\n",
    "def generate_training_data(row):\n",
    "    row = row[0]\n",
    "    ret = []\n",
    "    columns = ['ID', 'Frequency', 'InstlmentMode', 'LoanStatus', 'PaymentMode',\n",
    "       'BranchID', 'Area', 'Tenure', 'AssetCost', 'AmountFinance',\n",
    "       'DisbursalAmount', 'EMI', 'DisbursalDate', 'MaturityDAte', 'AuthDate',\n",
    "       'AssetID', 'ManufacturerID', 'SupplierID', 'LTV', 'SEX', 'AGE',\n",
    "       'MonthlyIncome', 'City', 'State', 'ZiPCODE']\n",
    "    column_tpes = ['int64', 'object', 'object', 'object', 'object', \n",
    "                   'int64', 'object', 'int64', 'int64','float64', \n",
    "                   'float64', 'float64',  '<M8[ns]', '<M8[ns]', '<M8[ns]',\n",
    "                   'int64', 'int64', 'int64', 'float64', 'object', \n",
    "                   'float64', 'float64', 'object', 'object', 'int64', 'object']\n",
    "    \n",
    "    for index in range(len(columns)):\n",
    "        if columns[index] in train_cat_cols:\n",
    "            \n",
    "            ret.extend(train_encode_cat_cols(row[index], columns[index], column_tpes[index]))\n",
    "\n",
    "        elif columns[index] in train_reg_cols:\n",
    "            ret.append(encode_reg_cols(row[index]))\n",
    "\n",
    "        elif columns[index] in train_date_cols:\n",
    "            ret.extend(encode_date_cols(row[index]))\n",
    "        else: pass\n",
    "    return np.array(ret)\n",
    "    \n",
    "def generate_datasets_to_train(train_dframe, bureau_df, val_size=.2):\n",
    "    ids = train_dframe[\"ID\"].unique()\n",
    "    np.random.shuffle(ids)\n",
    "    sp = int((1. - val_size) * ids.shape[0])\n",
    "    tr_ids, val_ids = ids[: sp], ids[sp:]\n",
    "    X_br, X_val_br = [], []\n",
    "    X, X_val = [], []\n",
    "    y, y_val = [], []\n",
    "    for i in tqdm(tr_ids):\n",
    "        \n",
    "#         X_br = Parallel(n_jobs=num_cores)(delayed(encode_df_for_user)(bureau_df[bureau_df.ID == i]))\n",
    "#         X = Parallel(n_jobs=num_cores)(delayed(generate_training_data)(train_dframe[train_dframe.ID == i].to_numpy()))\n",
    "        \n",
    "        \n",
    "        X_br.append(encode_df_for_user(bureau_df[bureau_df.ID == i]))\n",
    "        X.append(generate_training_data(train_dframe[train_dframe.ID == i].to_numpy()))\n",
    "        y.append(target_encoder.transform(train_dframe[train_dframe.ID == i][target_col].values))\n",
    "        \n",
    "    for i in tqdm(val_ids):\n",
    "#         X_val_br = Parallel(n_jobs=num_cores)(delayed(encode_df_for_user)(bureau_df[bureau_df.ID == i]))\n",
    "#         X_val = Parallel(n_jobs=num_cores)(delayed(generate_training_data)(train_dframe[train_dframe.ID == i].to_numpy()))\n",
    "        \n",
    "        \n",
    "        X_val_br.append(encode_df_for_user(bureau_df[bureau_df.ID == i]))\n",
    "        \n",
    "        X_val.append(generate_training_data(train_dframe[train_dframe.ID == i].to_numpy()))\n",
    "        y_val.append(target_encoder.transform(train_dframe[train_dframe.ID == i][target_col].values))\n",
    "    \n",
    "    \n",
    "    return np.array(X), np.array(X_val), np.array(X_br), np.array(X_val_br), np.array(y), np.array(y_val)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fecc08d6b4ba4dcca8862b773a7b02b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=80.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a867172cfb294466a505578c5f4487f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "z = generate_datasets_to_train(train_df.sample(100), df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80, 36), (20, 36), (80, 420, 205), (20, 420, 205), (80, 1), (20, 1))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[0].shape, z[1].shape, z[2].shape, z[3].shape, z[4].shape, z[5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(z, open(\"data.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "#     monitor='val_loss', min_delta=1e-2, patience=5, verbose=0, mode='auto',\n",
    "#     baseline=None, restore_best_weights=True)\n",
    "\n",
    "\n",
    "\n",
    "# model = keras.Sequential()\n",
    "# model.add(keras.layers.LSTM(64, kernel_initializer='he_uniform', batch_input_shape=(None, max_window, ts_feature_vector), return_sequences=True, name='encoder_1'))\n",
    "# model.add(keras.layers.LSTM(32, kernel_initializer='he_uniform', return_sequences=True, name='encoder_2'))\n",
    "# model.add(keras.layers.LSTM(16, kernel_initializer='he_uniform', return_sequences=False, name='encoder_3'))\n",
    "\n",
    "\n",
    "# model.add(keras.layers.TimeDistributed(keras.layers.Dense(ts_feature_vector)))\n",
    "# model.compile(loss=\"mse\",optimizer='adam')\n",
    "# print(model.summary())\n",
    "\n",
    "\n",
    "# model.fit(x=z[0], y=z[0], validation_data=(z[1], z[1]), epochs=10, batch_size=batch_size, shuffle=True, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got inputs shapes: [(None, 36), (None, 420, 36)]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-93703c28f28f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-93703c28f28f>\u001b[0m in \u001b[0;36mget_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mbureau_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m36\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'he_uniform'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbureau_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbureau_in\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpatialDropout1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/merge.py\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(inputs, axis, **kwargs)\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mconcatenation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minputs\u001b[0m \u001b[0malongside\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m   \"\"\"\n\u001b[0;32m--> 927\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    895\u001b[0m           \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2414\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2415\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2416\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2417\u001b[0m       \u001b[0;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m       \u001b[0;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(instance, input_shape)\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m       \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_tuples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m     \u001b[0;31m# Return shapes from `fn` as TensorShapes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/merge.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    508\u001b[0m       \u001b[0mranks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mshape_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mranks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m       \u001b[0;31m# Get the only rank for the set.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m       \u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mranks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got inputs shapes: [(None, 36), (None, 420, 36)]"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    train_in = Input(shape=(train_max_len, ))\n",
    "    bureau_in = Input(shape=(max_window, ts_feature_vector))\n",
    "    bureau_in = LSTM(128, kernel_initializer='he_uniform', return_sequences=True)(bureau_in)\n",
    "    bureau_in = LSTM(64, kernel_initializer='he_uniform', return_sequences=True)(bureau_in)\n",
    "    bureau_in = LSTM(36, kernel_initializer='he_uniform', return_sequences=True)(bureau_in)\n",
    "    \n",
    "    x = concatenate([train_in, bureau_in])\n",
    "    x = SpatialDropout1D(0.6)(x)\n",
    "    output = Dense(1, activation=\"sigmoid\")(x)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=[\"acc\"],\n",
    "    )\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "\n",
    "\n",
    "model.fit(x=[z[0], z[2]], y=z[4], validation_data=([z[1], z[3]], z[5]), epochs=10, batch_size=batch_size, shuffle=True, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
