{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SELF-INDICATOR</th>\n",
       "      <th>MATCH-TYPE</th>\n",
       "      <th>ACCT-TYPE</th>\n",
       "      <th>CONTRIBUTOR-TYPE</th>\n",
       "      <th>DATE-REPORTED</th>\n",
       "      <th>OWNERSHIP-IND</th>\n",
       "      <th>ACCOUNT-STATUS</th>\n",
       "      <th>DISBURSED-DT</th>\n",
       "      <th>CLOSE-DT</th>\n",
       "      <th>...</th>\n",
       "      <th>OVERDUE-AMT</th>\n",
       "      <th>WRITE-OFF-AMT</th>\n",
       "      <th>ASSET_CLASS</th>\n",
       "      <th>REPORTED DATE - HIST</th>\n",
       "      <th>DPD - HIST</th>\n",
       "      <th>CUR BAL - HIST</th>\n",
       "      <th>AMT OVERDUE - HIST</th>\n",
       "      <th>AMT PAID - HIST</th>\n",
       "      <th>TENURE</th>\n",
       "      <th>INSTALLMENT-TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>PRIMARY</td>\n",
       "      <td>Overdraft</td>\n",
       "      <td>NAB</td>\n",
       "      <td>2018-04-30</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Delinquent</td>\n",
       "      <td>2015-10-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>37873.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Standard</td>\n",
       "      <td>20180430,20180331,</td>\n",
       "      <td>030000</td>\n",
       "      <td>37873,12820,</td>\n",
       "      <td>37873,,</td>\n",
       "      <td>,,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>PRIMARY</td>\n",
       "      <td>Auto Loan (Personal)</td>\n",
       "      <td>NAB</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Active</td>\n",
       "      <td>2018-03-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Standard</td>\n",
       "      <td>20191231,20191130,20191031,20190930,20190831,2...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>20797,21988,23174,24341,25504,26648,27780,2891...</td>\n",
       "      <td>,,,,,,,,,,,,,,,,,,,,1452,,</td>\n",
       "      <td>,,,,,,,,,,,,,,,,,,,,,,</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Monthly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>PRIMARY</td>\n",
       "      <td>Tractor Loan</td>\n",
       "      <td>NBF</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Active</td>\n",
       "      <td>2019-08-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20200131,20191231,20191130,20191031,20190930,2...</td>\n",
       "      <td>000000000000000000</td>\n",
       "      <td>116087,116087,145000,145000,145000,145000,</td>\n",
       "      <td>0,0,0,0,0,0,</td>\n",
       "      <td>,,,,,,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>PRIMARY</td>\n",
       "      <td>Auto Loan (Personal)</td>\n",
       "      <td>NBF</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2013-09-27</td>\n",
       "      <td>2017-09-21</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20170930,20170801,20170731,20170630,20170531,2...</td>\n",
       "      <td>000DDD0270260270260270240270270000320000000000...</td>\n",
       "      <td>0,,15925,23754,31494,39147,46713,54194,61590,6...</td>\n",
       "      <td>0,,1014,1014,1014,1014,1014,1014,1014,983,0,92...</td>\n",
       "      <td>,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>PRIMARY</td>\n",
       "      <td>Tractor Loan</td>\n",
       "      <td>NBF</td>\n",
       "      <td>2016-02-29</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2012-02-10</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160229,20160131,20151231,20151130,20151031,2...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0,0,23658,23321,22989,46321,45662,45012,68030,...</td>\n",
       "      <td>0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...</td>\n",
       "      <td>,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  SELF-INDICATOR MATCH-TYPE             ACCT-TYPE CONTRIBUTOR-TYPE  \\\n",
       "0   1           False    PRIMARY             Overdraft              NAB   \n",
       "1   1           False    PRIMARY  Auto Loan (Personal)              NAB   \n",
       "2   1            True    PRIMARY          Tractor Loan              NBF   \n",
       "3   1            True    PRIMARY  Auto Loan (Personal)              NBF   \n",
       "4   1            True    PRIMARY          Tractor Loan              NBF   \n",
       "\n",
       "  DATE-REPORTED OWNERSHIP-IND ACCOUNT-STATUS DISBURSED-DT    CLOSE-DT  ...  \\\n",
       "0    2018-04-30    Individual     Delinquent   2015-10-05         NaN  ...   \n",
       "1    2019-12-31    Individual         Active   2018-03-19         NaN  ...   \n",
       "2    2020-01-31    Individual         Active   2019-08-30         NaN  ...   \n",
       "3    2017-09-30    Individual         Closed   2013-09-27  2017-09-21  ...   \n",
       "4    2016-02-29    Individual         Closed   2012-02-10  2016-02-01  ...   \n",
       "\n",
       "  OVERDUE-AMT  WRITE-OFF-AMT  ASSET_CLASS  \\\n",
       "0     37873.0            0.0     Standard   \n",
       "1         NaN            0.0     Standard   \n",
       "2         0.0            0.0          NaN   \n",
       "3         0.0            0.0          NaN   \n",
       "4         0.0            0.0          NaN   \n",
       "\n",
       "                                REPORTED DATE - HIST  \\\n",
       "0                                 20180430,20180331,   \n",
       "1  20191231,20191130,20191031,20190930,20190831,2...   \n",
       "2  20200131,20191231,20191130,20191031,20190930,2...   \n",
       "3  20170930,20170801,20170731,20170630,20170531,2...   \n",
       "4  20160229,20160131,20151231,20151130,20151031,2...   \n",
       "\n",
       "                                          DPD - HIST  \\\n",
       "0                                             030000   \n",
       "1  0000000000000000000000000000000000000000000000...   \n",
       "2                                 000000000000000000   \n",
       "3  000DDD0270260270260270240270270000320000000000...   \n",
       "4  0000000000000000000000000000000000000000000000...   \n",
       "\n",
       "                                      CUR BAL - HIST  \\\n",
       "0                                       37873,12820,   \n",
       "1  20797,21988,23174,24341,25504,26648,27780,2891...   \n",
       "2         116087,116087,145000,145000,145000,145000,   \n",
       "3  0,,15925,23754,31494,39147,46713,54194,61590,6...   \n",
       "4  0,0,23658,23321,22989,46321,45662,45012,68030,...   \n",
       "\n",
       "                                  AMT OVERDUE - HIST  \\\n",
       "0                                            37873,,   \n",
       "1                         ,,,,,,,,,,,,,,,,,,,,1452,,   \n",
       "2                                       0,0,0,0,0,0,   \n",
       "3  0,,1014,1014,1014,1014,1014,1014,1014,983,0,92...   \n",
       "4  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...   \n",
       "\n",
       "                         AMT PAID - HIST TENURE INSTALLMENT-TYPE  \n",
       "0                                     ,,    NaN              NaN  \n",
       "1                 ,,,,,,,,,,,,,,,,,,,,,,   36.0          Monthly  \n",
       "2                                 ,,,,,,    NaN              NaN  \n",
       "3  ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,    NaN              NaN  \n",
       "4  ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,    NaN              NaN  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tqdm.notebook import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import pickle as pkl\n",
    "from tensorflow.keras.layers import LSTM, Dense, TimeDistributed, Embedding, Bidirectional, Dropout, concatenate, SpatialDropout1D, GlobalMaxPooling1D, Reshape, MaxPooling1D, Flatten, Conv1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "df = pd.read_csv(\"Train/cleaned_bureau.csv\")\n",
    "tdf = pd.read_csv(\"Test/cleaned_bureau.csv\")\n",
    "train_df = pd.read_csv(\"Train/cleaned_train.csv\")\n",
    "test_df = pd.read_csv(\"Test/cleaned_train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71060     420\n",
       "141732    165\n",
       "51786     152\n",
       "1167      138\n",
       "97794     124\n",
       "         ... \n",
       "107223      1\n",
       "109270      1\n",
       "116205      1\n",
       "103121      1\n",
       "9436        1\n",
       "Name: ID, Length: 128655, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ID.value_counts(sort=True, ascending=False), df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114111    93\n",
       "114063    60\n",
       "69953     59\n",
       "26305     59\n",
       "114125    56\n",
       "          ..\n",
       "78473      1\n",
       "141962     1\n",
       "62097      1\n",
       "141994     1\n",
       "98272      1\n",
       "Name: ID, Length: 14745, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdf.ID.value_counts(sort=True, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['SELF-INDICATOR', 'MATCH-TYPE', 'ACCT-TYPE', 'CONTRIBUTOR-TYPE',\n",
    "       'OWNERSHIP-IND', 'ACCOUNT-STATUS', 'INSTALLMENT-TYPE',\n",
    "       'ASSET_CLASS', 'INSTALLMENT-FREQUENCY',\n",
    "       'DPD - HIST']    #should not be here\n",
    "date_cols = ['DATE-REPORTED',  'DISBURSED-DT', 'CLOSE-DT', \n",
    "             'LAST-PAYMENT-DATE']\n",
    "reg_cols = ['CREDIT-LIMIT/SANC AMT', 'DISBURSED-AMT/HIGH CREDIT', 'INSTALLMENT-AMT', 'CURRENT-BAL',\n",
    "        'OVERDUE-AMT', 'WRITE-OFF-AMT', 'TENURE'] # , 'DPD - HIST']\n",
    "array_cols = ['REPORTED DATE - HIST', 'CUR BAL - HIST',\n",
    "       'AMT OVERDUE - HIST', 'AMT PAID - HIST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, (560844, 26))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat_cols) + len(date_cols) + len(reg_cols) + len(array_cols), df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all([df[i].dtype in (\"bool\" ,\"object\") for i in cat_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all([df[i].dtype == \"float64\" for i in reg_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATE-REPORTED          3683\n",
       "DISBURSED-DT          32150\n",
       "CLOSE-DT             251827\n",
       "LAST-PAYMENT-DATE    319283\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[date_cols].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATE-REPORTED          3683\n",
       "DISBURSED-DT          32150\n",
       "CLOSE-DT             251827\n",
       "LAST-PAYMENT-DATE    319283\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in date_cols:\n",
    "    df[col] = pd.to_datetime(df[col])\n",
    "    tdf[col] = pd.to_datetime(tdf[col])\n",
    "df[date_cols].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max train 37.0\n",
      "max test 37.0\n",
      "max train 37.0\n",
      "max test 37.0\n",
      "max train 42.0\n",
      "max test 37.0\n",
      "max train 38.0\n",
      "max test 38.0\n"
     ]
    }
   ],
   "source": [
    "def get_length(amt):    \n",
    "    if not pd.isnull(amt):\n",
    "        return len(amt.split(\",\"))\n",
    "    else: 0\n",
    "        \n",
    "for col in array_cols:\n",
    "    print(\"max train {}\".format(df[col].apply(lambda x: get_length(x)).max()))\n",
    "    \n",
    "    print(\"max test {}\".format(tdf[col].apply(lambda x: get_length(x)).max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_window = 420\n",
    "ts_feature_vector = 205\n",
    "max_array_size = 42\n",
    "label_encoder_dict = {}\n",
    "num_cores = 7\n",
    "\n",
    "def encode_reg_cols(x):\n",
    "    if pd.isnull(x):\n",
    "        return 0.\n",
    "    return np.float64(x)\n",
    "\n",
    "def encode_array_cols(x):\n",
    "    if pd.isnull(x):\n",
    "        return [0] * max_array_size\n",
    "    else:\n",
    "        ret = []\n",
    "        for val in x.split(\",\"):\n",
    "            try:\n",
    "                ret.append(np.float32(val))\n",
    "            except:\n",
    "                ret.append(0.)\n",
    "#         while len(ret) < max_array_size:\n",
    "#             ret.insert(0, 0.)\n",
    "        return ret\n",
    "\n",
    "\n",
    "def encode_date_cols(x):\n",
    "    if pd.isnull(x):\n",
    "        return [-1., -1., -1., -1., -1.]\n",
    "    else:\n",
    "        return np.array([x.hour, x.minute, x.day, x.month, x.year], dtype=np.float64)\n",
    "\n",
    "\n",
    "def encode_cat_cols(x, col):\n",
    "\n",
    "    if pd.isnull(x): x = str(x)\n",
    "    return np.array(label_encoder_dict[col].transform([x]), dtype=np.float64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb59c169fe934f2e90e6a79d4316272a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELF-INDICATOR\n",
      "MATCH-TYPE\n",
      "ACCT-TYPE\n",
      "CONTRIBUTOR-TYPE\n",
      "OWNERSHIP-IND\n",
      "ACCOUNT-STATUS\n",
      "INSTALLMENT-TYPE\n",
      "ASSET_CLASS\n",
      "INSTALLMENT-FREQUENCY\n",
      "DPD - HIST\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for col in tqdm(cat_cols):\n",
    "    if col not in label_encoder_dict:\n",
    "        label_encoder_dict[col] = LabelEncoder()\n",
    "    print(col)\n",
    "    label_encoder_dict[col].fit(df[col].append(tdf[col]).fillna(\"nan\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = df[df.ID == 141732]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_df_for_user(dframe):\n",
    "    \n",
    "    final = []\n",
    "    for index, row in dframe.iterrows():\n",
    "        \n",
    "        l = []\n",
    "        ret = np.array([], dtype=np.float64)\n",
    "    \n",
    "        # 10 * 1\n",
    "        for col in cat_cols:\n",
    "#             print(ret, encode_cat_cols(row[col], col))\n",
    "            ret = np.concatenate((ret, encode_cat_cols(row[col], col)))\n",
    "        \n",
    "        # 7 * 1 = 7\n",
    "        for col in reg_cols:\n",
    "#             print(np.array([encode_reg_cols(row[col])]))\n",
    "#             print(ret)\n",
    "            ret = np.concatenate((ret, np.array([encode_reg_cols(row[col])])))\n",
    "        \n",
    "        # 5 * 4 = 20\n",
    "        for col in date_cols:\n",
    "            ret = np.concatenate((ret, encode_date_cols(row[col])))\n",
    "            \n",
    "        \n",
    "        # 4 * 42 = 168\n",
    "        for col in array_cols:\n",
    "            l.append(encode_array_cols(row[col]))\n",
    "            \n",
    "        ret = np.concatenate((ret, np.array(tf.keras.preprocessing.sequence.pad_sequences(l, maxlen=max_array_size, padding='pre')).flatten()))\n",
    "        assert len(ret) == ts_feature_vector, print(len(l), len(l[0]))\n",
    "        final.append(ret)\n",
    "    while len(final) < max_window:\n",
    "        final.insert(0, [0.] * ts_feature_vector)\n",
    "#     assert len(final) == max_window\n",
    "    return np.array(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(420, 205)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_df_for_user(temp_df).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2dc408e12d44318a18beab47aa3f8ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency\n",
      "InstlmentMode\n",
      "LoanStatus\n",
      "PaymentMode\n",
      "BranchID\n",
      "Area\n",
      "ManufacturerID\n",
      "SupplierID\n",
      "SEX\n",
      "City\n",
      "State\n",
      "ZiPCODE\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashutosh/miniconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_label_encoders = {}\n",
    "target_encoder = LabelEncoder()\n",
    "\n",
    "\n",
    "\n",
    "train_cat_cols = ['Frequency', 'InstlmentMode', 'LoanStatus', 'PaymentMode', 'BranchID', 'Area', \n",
    "            'ManufacturerID', 'SupplierID', 'SEX', 'City', 'State', 'ZiPCODE']\n",
    "target_col = ['Top-up Month']\n",
    "train_reg_cols = ['AmountFinance', 'DisbursalAmount', 'EMI', 'AssetID', 'MonthlyIncome', 'Tenure', 'AssetCost', 'LTV', 'AGE']\n",
    "train_date_cols = ['DisbursalDate', 'MaturityDAte', 'AuthDate']\n",
    "\n",
    "for col in train_date_cols:\n",
    "    train_df[col] = pd.to_datetime(train_df[col], errors=\"coerce\")\n",
    "    test_df[col] = pd.to_datetime(test_df[col], errors=\"coerce\")\n",
    "    \n",
    "for col in tqdm(train_cat_cols):\n",
    "    if col not in train_label_encoders:\n",
    "        train_label_encoders[col] = LabelEncoder()\n",
    "    print(col)\n",
    "    fill_val = -1 if train_df[col].dtype == \"int64\" else \"nan\"\n",
    "    if col == target_col[0]:\n",
    "        train_label_encoders[col].fit(train_df[col].fillna(fill_val))\n",
    "\n",
    "    else: train_label_encoders[col].fit(train_df[col].append(test_df[col]).fillna(fill_val))\n",
    "\n",
    "target_encoder.fit(train_df[target_col])\n",
    "\n",
    "def train_encode_cat_cols(x, col, tpe):\n",
    "\n",
    "    if pd.isnull(x): \n",
    "        if tpe == \"object\": x = str(x)\n",
    "        elif x == \"int64\": x = 0\n",
    "        else: assert False\n",
    "        \n",
    "    return train_label_encoders[col].transform([x])   \n",
    "\n",
    "def encode_target(x):\n",
    "    return target_encoder.transform(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_max_len = 36\n",
    "def generate_training_data(row):\n",
    "    row = row[0]\n",
    "    ret = []\n",
    "    columns = ['ID', 'Frequency', 'InstlmentMode', 'LoanStatus', 'PaymentMode',\n",
    "       'BranchID', 'Area', 'Tenure', 'AssetCost', 'AmountFinance',\n",
    "       'DisbursalAmount', 'EMI', 'DisbursalDate', 'MaturityDAte', 'AuthDate',\n",
    "       'AssetID', 'ManufacturerID', 'SupplierID', 'LTV', 'SEX', 'AGE',\n",
    "       'MonthlyIncome', 'City', 'State', 'ZiPCODE']\n",
    "    column_tpes = ['int64', 'object', 'object', 'object', 'object', \n",
    "                   'int64', 'object', 'int64', 'int64','float64', \n",
    "                   'float64', 'float64',  '<M8[ns]', '<M8[ns]', '<M8[ns]',\n",
    "                   'int64', 'int64', 'int64', 'float64', 'object', \n",
    "                   'float64', 'float64', 'object', 'object', 'int64', 'object']\n",
    "    \n",
    "    for index in range(len(columns)):\n",
    "        if columns[index] in train_cat_cols:\n",
    "            \n",
    "            ret.extend(train_encode_cat_cols(row[index], columns[index], column_tpes[index]))\n",
    "\n",
    "        elif columns[index] in train_reg_cols:\n",
    "            ret.append(encode_reg_cols(row[index]))\n",
    "\n",
    "        elif columns[index] in train_date_cols:\n",
    "            ret.extend(encode_date_cols(row[index]))\n",
    "        else: pass\n",
    "    return np.array(ret)\n",
    "    \n",
    "def generate_datasets_to_train(train_dframe, bureau_df, val_size=.2):\n",
    "    ids = train_dframe[\"ID\"].unique()\n",
    "    np.random.shuffle(ids)\n",
    "    sp = int((1. - val_size) * ids.shape[0])\n",
    "    tr_ids, val_ids = ids[: sp], ids[sp:]\n",
    "#     X_br, X_val_br = [], []\n",
    "#     X, X_val = [], []\n",
    "    y, y_val = [], []\n",
    "    \n",
    "    \n",
    "    X = Parallel(n_jobs=num_cores)(delayed(generate_training_data)(train_dframe[train_dframe.ID == i].to_numpy()) for i in tqdm(tr_ids, total=len(tr_ids)))\n",
    "    X_br = Parallel(n_jobs=num_cores)(delayed(encode_df_for_user)(bureau_df[bureau_df.ID == i]) for i in tqdm(tr_ids, total=len(tr_ids)))\n",
    "    \n",
    "    X_val = Parallel(n_jobs=num_cores)(delayed(generate_training_data)(train_dframe[train_dframe.ID == i].to_numpy()) for i in tqdm(val_ids, total=len(val_ids)))\n",
    "    X_val_br = Parallel(n_jobs=num_cores)(delayed(encode_df_for_user)(bureau_df[bureau_df.ID == i]) for i in tqdm(val_ids, total=len(val_ids)))\n",
    "    \n",
    "\n",
    "    for i in tqdm(tr_ids):\n",
    "        \n",
    "#         X = Parallel(n_jobs=num_cores)(delayed(generate_training_data)(train_dframe[train_dframe.ID == i].to_numpy()))\n",
    "        \n",
    "        \n",
    "#         X_br.append(encode_df_for_user(bureau_df[bureau_df.ID == i]))\n",
    "#         X.append(generate_training_data(train_dframe[train_dframe.ID == i].to_numpy()))\n",
    "        y.append(target_encoder.transform(train_dframe[train_dframe.ID == i][target_col].values))\n",
    "        \n",
    "    for i in tqdm(val_ids):\n",
    "#         X_val_br = Parallel(n_jobs=num_cores)(delayed(encode_df_for_user)(bureau_df[bureau_df.ID == i]))\n",
    "#         X_val = Parallel(n_jobs=num_cores)(delayed(generate_training_data)(train_dframe[train_dframe.ID == i].to_numpy()))\n",
    "        \n",
    "        \n",
    "#         X_val_br.append(encode_df_for_user(bureau_df[bureau_df.ID == i]))\n",
    "        \n",
    "#         X_val.append(generate_training_data(train_dframe[train_dframe.ID == i].to_numpy()))\n",
    "        y_val.append(target_encoder.transform(train_dframe[train_dframe.ID == i][target_col].values))\n",
    "    \n",
    "    \n",
    "    return np.array(X), np.array(X_val), np.array(X_br), np.array(X_val_br), np.array(y), np.array(y_val)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4b305590d8c4bb0baf42c38aa3ff329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=800.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11ed5e92800d44ddaa708317d0436a9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=800.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f39db99b658482297cb5a23dadc788c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f9d95b9ed854bf9a15b6a68208133d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30df942190814af4becdf2024cd82a6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=800.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41ba5c6d84e1409e9a5017c3a2aa44b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "z = generate_datasets_to_train(train_df.head(60000), df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800, 36), (200, 36), (800, 420, 205), (200, 420, 205), (800, 1), (200, 1))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[0].shape, z[1].shape, z[2].shape, z[3].shape, z[4].shape, z[5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(z, open(\"data.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_17 (InputLayer)           [(None, 420, 205)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_21 (LSTM)                  (None, 420, 128)     171008      input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_16 (InputLayer)           [(None, 36)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_22 (LSTM)                  (None, 420, 64)      49408       lstm_21[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 32)           1184        input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_23 (LSTM)                  (None, 420, 36)      14544       lstm_22[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 32)           0           dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 15120)        0           lstm_23[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 15152)        0           dropout_9[0][0]                  \n",
      "                                                                 reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 15152)        0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 32)           484896      dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 1)            33          dense_18[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 721,073\n",
      "Trainable params: 721,073\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "[0 1 2 3 4 5 6]\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 4s 147ms/step - loss: 6.3106e-07 - acc: 0.0088 - val_loss: 6.1750e-07 - val_acc: 0.0250\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 3s 119ms/step - loss: 6.3106e-07 - acc: 0.0450 - val_loss: 6.1750e-07 - val_acc: 0.0750\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 3s 119ms/step - loss: 6.3106e-07 - acc: 0.0787 - val_loss: 6.1750e-07 - val_acc: 0.0750\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 3s 117ms/step - loss: 6.3106e-07 - acc: 0.0787 - val_loss: 6.1750e-07 - val_acc: 0.0750\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 3s 116ms/step - loss: 6.3106e-07 - acc: 0.0787 - val_loss: 6.1750e-07 - val_acc: 0.0750\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 3s 115ms/step - loss: 6.3106e-07 - acc: 0.0787 - val_loss: 6.1750e-07 - val_acc: 0.0750\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 3s 115ms/step - loss: 6.3106e-07 - acc: 0.0787 - val_loss: 6.1750e-07 - val_acc: 0.0750\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 3s 115ms/step - loss: 6.3106e-07 - acc: 0.0787 - val_loss: 6.1750e-07 - val_acc: 0.0750\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 3s 115ms/step - loss: 6.3106e-07 - acc: 0.0787 - val_loss: 6.1750e-07 - val_acc: 0.0750\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 3s 115ms/step - loss: 6.3106e-07 - acc: 0.0787 - val_loss: 6.1750e-07 - val_acc: 0.0750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2cda855350>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def get_model():\n",
    "#     train_in = Input(shape=(train_max_len, ))\n",
    "#     train_int = Dense(32,activation=\"relu\")(train_in)\n",
    "#     train_int = Dropout(.2, seed=42)(train_int)\n",
    "#     bureau_in = Input(shape=(max_window, ts_feature_vector))\n",
    "#     bureau_int = LSTM(128, kernel_initializer='he_uniform', return_sequences=True)(bureau_in)\n",
    "#     bureau_int = LSTM(64, kernel_initializer='he_uniform', return_sequences=True)(bureau_int)\n",
    "#     bureau_int = LSTM(36, kernel_initializer='he_uniform', return_sequences=True)(bureau_int)\n",
    "#     bureau_int = Reshape((420*36,), input_shape=(None, 420, 36))(bureau_int)\n",
    "#     x = concatenate([train_int, bureau_int])\n",
    "#     x = Dropout(.2, seed=42)(x)\n",
    "    \n",
    "#     x = Dense(32,activation=\"relu\")(x)\n",
    "#     output = Dense(1, activation=\"sigmoid\")(x)\n",
    "#     model = Model([train_in, bureau_in], output)\n",
    "#     model.compile(\n",
    "#         optimizer=tf.keras.optimizers.Adam(),\n",
    "#         loss='categorical_crossentropy',\n",
    "#         metrics=[\"acc\"],\n",
    "#     )\n",
    "#     print(model.summary())\n",
    "#     return model\n",
    "\n",
    "# model = get_model()\n",
    "\n",
    "# print(np.unique(z[4]))\n",
    "# model.fit(x=[z[0], z[2]], y=z[4], validation_data=([z[1], z[3]], z[5]), epochs=10, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
